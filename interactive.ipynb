{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cd3432-2dff-40a1-a1aa-d3454da28365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1 Initialize notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f0f5c-8f68-4b41-ae23-59170bf1c586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a8932-385e-4a44-9916-a48e01cfbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import re\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage, spatial, stats\n",
    "import seaborn as sns\n",
    "import trackpy as tp\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f3d43-18e8-4c3d-9a2a-666139c3196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collections import *\n",
    "from image_analysis import *\n",
    "from event_detection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09e8c4-e11d-4f46-b51f-bd56a8fbfe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa03c0-5bbd-4788-8dde-7912d3533300",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.2 Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979501c-2734-4531-8233-8f65e2edf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style options for graphs\n",
    "mpl.rc('font', size=9)\n",
    "mpl.rc('axes', titlesize=9)\n",
    "mpl.rc('font', family='sans-serif') \n",
    "mpl.rc('font', serif='Arial')\n",
    "\n",
    "cm = 1 / 2.54  # centimeters in inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1daa5e-1f86-4c1d-b5a8-a6360b179141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors used in manuscript\n",
    "red = '#CE214C'\n",
    "orange = '#F36F32'\n",
    "gold = '#F0BE08'\n",
    "green = '#16A970'\n",
    "cyan = '#13B4E1'\n",
    "blue = '#1B1B87'\n",
    "magenta = '#BB178A'\n",
    "white = '#FFFFFF'\n",
    "gray = '#BBBBBB'\n",
    "black = '#000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a519c0a-72c3-42ea-a648-46e75d44343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa6743-95de-4b46-9bbd-675a3064b54b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.3 Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387414fa-616a-46c0-af2f-b483a3f6c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci(array, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Create confidence interval for population mean weight (default = 95%).\n",
    "    \"\"\"\n",
    "    return stats.t.interval(\n",
    "        confidence=confidence,\n",
    "        df=len(array)-1,\n",
    "        loc=np.mean(array),\n",
    "        scale=stats.sem(array),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c613d39-b9de-4508-a875-9bdacd2c7e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_group(df, by, on):\n",
    "    \"\"\"\n",
    "    Helper function to get DataFrame group.\n",
    "    \"\"\"\n",
    "    return df[df[by] == on]\n",
    "\n",
    "def apply(dict_in, func, keys=None, copy=False):\n",
    "    \"\"\"\n",
    "    Helper function to apply function to dict\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = dict_in.keys()\n",
    "    \n",
    "    if copy:\n",
    "        dict_in = copy.deepcopy(dict_in)\n",
    "    \n",
    "    result = {key : func(dict_in[key]) for key in keys}\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b6380-67a8-4a37-8e11-87518c1eef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_dicts(dfs_dict, channels, df_types=None, rounding=5, intensity='raw'):\n",
    "    \"\"\"\n",
    "    For a given experiment, merge requested data dictionaries together.\n",
    "    \"\"\"\n",
    "    \n",
    "    ndim = 3\n",
    "    axis_names = 'z', 'y', 'x'\n",
    "    px2um = {'z' : 0.210, 'y' : 0.104, 'x' : 0.104}\n",
    "    \n",
    "    #dfs_dict = self._data\n",
    "    if df_types is None:\n",
    "        df_types = dfs_dict.keys()\n",
    "    #channels = dfs_dict[list(df_types)[0]].keys()\n",
    "    \n",
    "    dfs_merged = dict()\n",
    "    for channel in channels:\n",
    "        # Merge on xyzt data for each particle (in px)\n",
    "        merge_columns = ['frame', 'z_px', 'y_px', 'x_px']\n",
    "\n",
    "        # Assume that blobs and intensities are available\n",
    "        df1 = dfs_dict['blobs'][channel].round(rounding)\n",
    "        df2 = dfs_dict['intensities'][channel].round(rounding)\n",
    "\n",
    "        # Merge blobs and intensities data\n",
    "        df = pd.merge(df1, df2, on=merge_columns)\n",
    "        \n",
    "        # Drop duplicates and sort data\n",
    "        df = df.drop_duplicates(subset=['z_px', 'y_px', 'x_px', 'frame'])\n",
    "        \n",
    "        for df_type in df_types:\n",
    "            try:\n",
    "                df3 = dfs_dict[df_type][channel].round(rounding)\n",
    "                if df_type in ('blobs', 'intensities'):\n",
    "                    # Skip previously merged data\n",
    "                    continue\n",
    "                elif df_type in ('tracked', ):\n",
    "                    # Rename tracked columns\n",
    "                    rename_columns = {'x' : 'x_um', 'y' : 'y_um', 'z' : 'z_um'}\n",
    "                    df3.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "                    # Merge tracked and intensities/blobs data on xyzt data (in um)\n",
    "                    merge_columns = ['frame', 'z_um', 'y_um', 'x_um']\n",
    "                    kep_columns = ['frame', 'z_um', 'y_um', 'x_um', 'track', 'segment', 'parent']\n",
    "                    df = pd.merge(df, df3[kep_columns], on=merge_columns)\n",
    "\n",
    "                    # Drop duplicates and sort data\n",
    "                    df = df.drop_duplicates(subset=['track', 'frame'])\n",
    "                    df = df.sort_values(by=['track', 'frame'])\n",
    "                else:\n",
    "                    # Merge based on frame and label\n",
    "                    df = pd.merge(df, df3, on=['frame', 'labels'])\n",
    "\n",
    "                    # Sort data\n",
    "                    df = df.sort_values(by=['frame', 'labels'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "        # Clean up the merged DataFrame\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Make a new column for the average radius (in pixels)\n",
    "        sigma_px = df.filter(regex='sigma').mean(axis=1)\n",
    "        df['r_px'] = sigma_px * np.sqrt(ndim)\n",
    "\n",
    "        # Make a new column for the average radius (in microns), assuming correct lateral dimensions\n",
    "        sigmas_um = df[['sigma_y', 'sigma_x']] * [px2um['y'], px2um['x']]\n",
    "        df['r_um'] = (sigmas_um * np.sqrt(ndim)).mean(axis=1)\n",
    "\n",
    "        # Save the merged DataFrame\n",
    "        dfs_merged[channel] = df\n",
    "    \n",
    "    return dfs_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d0488-1466-41f8-8ec0-304f6af5a0e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2 Import new datasets (_run once_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ab00d-2aa2-4d03-ad91-4848b32608fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1 Set import parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b7ad1-ae25-4b8f-8384-c58ab40b9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set analysis directory\n",
    "top_dir = '.'\n",
    "\n",
    "# Set condition for analysis\n",
    "condition = 'RPE1 WT'\n",
    "\n",
    "# Set experiment search pattern\n",
    "experiment_pattern = 'APPL1EEA1'\n",
    "\n",
    "# Predefine channels\n",
    "channel1, channel2 = channels = 'APPL1', 'EEA1'\n",
    "\n",
    "# Predefine data types each corresponding to set of CSV files for each channel\n",
    "data_types = 'tracked', 'collisions', 'conversions', 'intensities', 'blobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10c29a-6d48-4e37-941a-e100c922c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific column names\n",
    "track_columns = ['track_' + channel for channel in channels]\n",
    "id_columns = track_columns + ['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b14dd-529d-4242-9416-4e2601292d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channel-specific colors\n",
    "colors = {\n",
    "    channel1 : cyan,\n",
    "    channel2 : magenta,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdb46c-5b13-4ad9-b33c-f079e0e51232",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2 Load data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057372a3-4b23-4254-9b25-96147ff01ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis CSV files\n",
    "path_lists = list()\n",
    "data_dicts = list()\n",
    "\n",
    "condition_dir = os.path.join(top_dir, 'Tracking', condition)\n",
    "experiment_dirs = glob.glob(os.path.join(condition_dir, experiment_pattern))\n",
    "\n",
    "for experiment_dir in experiment_dirs:\n",
    "    if not os.path.isdir(experiment_dir): continue\n",
    "    cell_dirs = glob.glob(os.path.join(experiment_dir, '*'))\n",
    "    for cell_dir in cell_dirs:\n",
    "        if not os.path.isdir(cell_dir):\n",
    "            continue\n",
    "        print(cell_dir)\n",
    "        \n",
    "        csv_data = dict()\n",
    "        for data_type in data_types:\n",
    "            csv_data[data_type] = dict()\n",
    "            for channel in channels:\n",
    "                csv_path = os.path.join(cell_dir, data_type.title() + '_' + channel + '.csv')\n",
    "                try:\n",
    "                    csv_data[data_type][channel] = pd.read_csv(csv_path)\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "\n",
    "        path_lists.append(cell_dir)\n",
    "        data_dicts.append(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7d3ea-c83e-4bed-bc60-62bd0d2fce05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.3 Check data based on conversions identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630848e-11ed-47fa-80cf-bfe72fbae7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(condition.upper())\n",
    "for cell_index, data_dict in enumerate(data_dicts):\n",
    "    # Attempt to read relevant data dicts\n",
    "    try:\n",
    "        tracked = data_dict['tracked'][channel1]\n",
    "        conversions = data_dict['conversions'][channel1].drop_duplicates(subset=track_columns)\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "    # Read out number of possible and likely conversions\n",
    "    convert_lens = (conversions[conversions['conversion'] == True]\n",
    "                    .filter(like='overlap')\n",
    "                    .diff(axis=1)\n",
    "                    ['overlap_stop']\n",
    "                    .values\n",
    "                   )\n",
    "    convert_keep = convert_lens > 4\n",
    "    overlap_count = len(convert_lens)\n",
    "    convert_count = len(convert_lens[convert_keep])\n",
    "\n",
    "    # Collect basis statistics\n",
    "    if overlap_count > 0:\n",
    "        convert_pct = 100 * convert_count / overlap_count\n",
    "    else:\n",
    "        convert_pct = 0\n",
    "\n",
    "    # Print results to screen\n",
    "    cell_name = ', '.join(path_lists[cell_index].split(os.sep)[-2:])\n",
    "    message = f\"  {cell_name} : {convert_count:d} likely conversions ({convert_pct:0.1f}%)\"\n",
    "    if convert_pct > 0:\n",
    "        message += f\"; median length = {np.median(convert_lens[convert_keep])}\"\n",
    "        message += f\"; max length = {np.max(convert_lens)}\"\n",
    "\n",
    "    print(message)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0a874-f9ce-47ff-b85a-d5381d031885",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.4 Combine data from each condition together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289cb72b-03c5-4dd7-a639-cd65dcaf8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_type in data_types:\n",
    "    data_dfs = dict()\n",
    "    for channel in channels:\n",
    "        data_dfs[channel] = list()\n",
    "        for data_dict, path_list in zip(data_dicts, path_lists):\n",
    "            condition, experiment, cell_name = path_list.split(os.sep)[-3:]\n",
    "            if data_type == 'tracked':\n",
    "                data_dict[data_type] = merge_data_dicts(data_dict, channels, ('blobs', 'tracked', 'intensities'))\n",
    "                \n",
    "            if channel in data_dict[data_type]:\n",
    "                data_df = data_dict[data_type][channel]\n",
    "                if condition == '_Senthil':\n",
    "                    data_df['condition'] = 'RPE1 WT'\n",
    "                    data_df['movie'] = int(cell_name.replace('cell', ''))\n",
    "                else:\n",
    "                    data_df['movie'] = cell_name\n",
    "                data_dfs[channel].append(data_df)\n",
    "        if channel in data_dfs and len(data_dfs[channel]) > 0:\n",
    "            data_dfs[channel] = pd.concat(data_dfs[channel])\n",
    "    \n",
    "    if data_type == 'tracked':\n",
    "        tracked1 = data_dfs[channel1]\n",
    "        tracked2 = data_dfs[channel2]\n",
    "    elif data_type == 'collisions':\n",
    "        collisions = data_dfs[channel1]\n",
    "    elif data_type == 'conversions':\n",
    "        conversions = data_dfs[channel1]\n",
    "\n",
    "collisions.drop_duplicates(ignore_index=True, inplace=True)\n",
    "conversions.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5f7df-84b3-4a6f-abda-1c57e7068522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame rates of each movie\n",
    "DEFAULT_FRAME_RATE = 2.6\n",
    "movie_list = tuple(tracked1['movie'].unique())\n",
    "frame_rates = dict.fromkeys(movie_list)\n",
    "\n",
    "for movie in movie_list:\n",
    "    try:\n",
    "        match = re.search(r'([\\d.]*)spv', movie)\n",
    "        if match:\n",
    "            frame_rate = float(match.group(1))\n",
    "        else:\n",
    "            print(movie)\n",
    "            frame_rate = DEFAULT_FRAME_RATE\n",
    "    except:\n",
    "        frame_rate = DEFAULT_FRAME_RATE\n",
    "    frame_rates[movie] = frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5680cd-c44e-42e0-9012-f74b3250a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from each movie into a DataFrame\n",
    "data1 = list()\n",
    "data2 = list()\n",
    "buckets = list()\n",
    "\n",
    "for movie in movie_list:\n",
    "    event = 0\n",
    "    \n",
    "    # Get all conversions for the current movie\n",
    "    df = conversions.groupby('movie').get_group(movie)\n",
    "    \n",
    "    # Get all frames for the current movie\n",
    "    frames = tracked1.groupby('movie').get_group(movie)['frame'].unique()\n",
    "\n",
    "    # Remove tracks starting and ending with the movie\n",
    "    interior = (df['overlap_start'] > frames.min()) & (df['overlap_stop'] < frames.max())\n",
    "    df = df[interior]\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        event += 1\n",
    "        \n",
    "        track1, track2 = row[track_columns]\n",
    "        t1 = tracked1.groupby(['movie', 'track']).get_group((movie, track1))\n",
    "        t2 = tracked2.groupby(['movie', 'track']).get_group((movie, track2))\n",
    "        \n",
    "        # Save data results for APPL1\n",
    "        df1 = t1.filter(like='signal')\n",
    "        try:\n",
    "            df1 = df1.apply(lambda y : signal.savgol_filter(y, 3, 1))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        df1['frame_abs'] = t1['frame']\n",
    "        df1['time_abs'] = df1['frame_abs'] * frame_rate\n",
    "        df1['frame'] = t1['frame'] - row['overlap_start']\n",
    "        df1['time'] = df1['frame'] * frame_rate\n",
    "        df1['length'] = row['overlap_stop'] - row['overlap_start'] + 1\n",
    "        df1['conversion'] = row['conversion']\n",
    "        df1['event'] = event\n",
    "        df1['movie'] = movie\n",
    "        df1['track_'+channel1] = row['track_'+channel1]\n",
    "        df1['track_'+channel2] = row['track_'+channel2]\n",
    "        df1['r_um'] = t1['r_um']\n",
    "        df1['V_um'] = (4 * np.pi / 3) * df1['r_um'] ** 3\n",
    "        \n",
    "        # Save data results for EEA1\n",
    "        df2 = t2.filter(like='signal')\n",
    "        try:\n",
    "            df2 = df2.apply(lambda y : signal.savgol_filter(y, 3, 1))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        df2['frame_abs'] = t2['frame']\n",
    "        df2['time_abs'] = df2['frame_abs'] * frame_rate\n",
    "        df2['frame'] = t2['frame'] - row['overlap_start']\n",
    "        df2['time'] = df2['frame'] * frame_rate\n",
    "        df2['length'] = row['overlap_stop'] - row['overlap_start'] + 1\n",
    "        df2['conversion'] = row['conversion']\n",
    "        df2['event'] = event\n",
    "        df2['movie'] = movie\n",
    "        df2['track_'+channel1] = row['track_'+channel1]\n",
    "        df2['track_'+channel2] = row['track_'+channel2]\n",
    "        df2['r_um'] = t2['r_um']\n",
    "        df2['V_um'] = (4 * np.pi / 3) * df2['r_um'] ** 3\n",
    "        \n",
    "        \n",
    "        # Filter based on decrease in APPL1 / increased in EEA1\n",
    "        start1, start2 = (df1[(df1['frame'] >= 0) & \n",
    "                              (df1['frame'] < df1['length'] / 5)]\n",
    "                           .filter(like='sub').mean(axis=0)[['signal_sub_'+channel1, 'signal_sub_'+channel2]].values)\n",
    "        stop1, stop2 = (df1[(df1['frame'] < df1['length']) & \n",
    "                            (df1['frame'] >= df1['length'] / 5)]\n",
    "                         .filter(like='sub').mean(axis=0)[['signal_sub_'+channel1, 'signal_sub_'+channel2]].values)\n",
    "        \n",
    "        # Save threshold criteria for filtering results\n",
    "        bucket = {'track_'+channel1 : track1, \n",
    "                  'track_'+channel2 : track2, \n",
    "                  'movie' : movie, 'event' : event}\n",
    "        bucket['tracked_during_'+channel1] = row['overlap_start'] in t1['frame'].values\n",
    "        bucket['tracked_during_'+channel2] = row['overlap_start'] in t2['frame'].values\n",
    "        bucket['decrease_during_'+channel1] = stop1 < start1\n",
    "        \n",
    "        bucket['increase_during_'+channel2] = stop2 > start2\n",
    "        bucket['started_before_'+channel1] = row['track_'+channel1+'_start'] < row['overlap_start']\n",
    "        bucket['started_during_'+channel2] = row['track_'+channel2+'_start'] >= row['overlap_start']\n",
    "        bucket['stopped_during_'+channel1] = row['track_'+channel1+'_stop'] <= row['overlap_stop']\n",
    "        bucket['continued_after_'+channel2] = row['track_'+channel2+'_stop'] > row['overlap_stop']\n",
    "        \n",
    "        buckets.append(bucket)\n",
    "        \n",
    "        data1.append(df1)\n",
    "        data2.append(df2)\n",
    "\n",
    "buckets = pd.DataFrame(buckets)\n",
    "data1 = pd.concat(data1, ignore_index=True)\n",
    "data2 = pd.concat(data2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ed828-4420-4825-aea1-ef59175cff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate tracks and movies\n",
    "tracks1, tracks2, movies = map(np.asarray, zip(*conversions[id_columns].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530c422-9587-4711-8e5d-4249d3ce3e2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.5 Save intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a9129-f3a1-4a74-bc08-a02fa64efce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate results will save to the following file\n",
    "csv_name = f\"Dataset_{'+'.join(channels)}_{today}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b8698-e51a-4b91-89e8-f37c2a2fc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all data into a dict\n",
    "datasets = {\n",
    "    'Metadata' : {\n",
    "        'colors' : colors,\n",
    "        'channels' : channels,\n",
    "        'movie_list' : movie_list,\n",
    "        'frame_rates' : frame_rates,\n",
    "    },\n",
    "    'Filter1' : {\n",
    "        'tracks1' : tracks1,\n",
    "        'tracks2' : tracks2,\n",
    "        'movies' : movies,\n",
    "        'tracked1' : tracked1,\n",
    "        'tracked2' : tracked2,\n",
    "        'collisions' : collisions,\n",
    "        'conversions' : conversions,\n",
    "        'buckets': buckets,\n",
    "        'data1' : data1,\n",
    "        'data2' : data2,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(csv_name, 'wb') as f:\n",
    "    f.write(pickle.dumps(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c1830-f31b-47f8-970c-ee639fe4bb8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3 Check basic dataset statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc034-df97-4c9d-9b98-2d3752e794ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1 Import previous datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1aa56-5269-4b21-8b60-10b4f33ee1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proper CSV name (latest export by default)\n",
    "csv_index = -1\n",
    "csv_name = sorted(glob.glob('Dataset*.csv'))[csv_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e4041-f88e-44fe-9d6d-4181c2c92976",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_name, 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Gather all data into a dict\n",
    "channel1, channel2 = channels = datasets['Metadata']['channels']\n",
    "colors = datasets['Metadata']['colors']\n",
    "movie_list = datasets['Metadata']['movie_list']\n",
    "frame_rates = datasets['Metadata']['frame_rates']\n",
    "\n",
    "tracks1 = copy.deepcopy(datasets['Filter1']['tracks1'])\n",
    "tracks2 = copy.deepcopy(datasets['Filter1']['tracks2'])\n",
    "movies = copy.deepcopy(datasets['Filter1']['movies'])\n",
    "\n",
    "tracked1 = copy.deepcopy(datasets['Filter1']['tracked1'])\n",
    "tracked2 = copy.deepcopy(datasets['Filter1']['tracked2'])\n",
    "collisions = copy.deepcopy(datasets['Filter1']['collisions'])\n",
    "conversions = copy.deepcopy(datasets['Filter1']['conversions'])\n",
    "\n",
    "buckets = copy.deepcopy(datasets['Filter1']['buckets'])\n",
    "data1 = copy.deepcopy(datasets['Filter1']['data1'])\n",
    "data2 = copy.deepcopy(datasets['Filter1']['data2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8c9b9-5b34-49b0-adf6-59b0f64913a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific column names\n",
    "track_columns = ['track_' + channel for channel in channels]\n",
    "id_columns = track_columns + ['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007bb536-233a-407b-af7c-97ed353c0797",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Tracked particle lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d8681-2b43-4f84-81f5-165e4bc2da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'Tracked'\n",
    "scale = 'linear'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for channel, df in zip(channels, (tracked1, tracked2)):\n",
    "    hist, bins = np.histogram(np.bincount(df['track'].astype(int)), bins=np.arange(df['frame'].min(), df['frame'].max() + 1), density=True)\n",
    "    ax.step(bins[1:], hist[0:], color=colors[channel], label=channel)\n",
    "ax.set_ylabel('relative frequency')\n",
    "ax.set_xlabel('track length (frames)')\n",
    "ax.set_xlim(1e0, 1e+2)\n",
    "ax.set_ylim(1e-6, 1e-1)\n",
    "ax.set_xscale(scale)\n",
    "ax.set_yscale(scale)\n",
    "ax.legend()\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589983eb-b4ad-49ee-aff1-1a88fcbb4286",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.3 Step lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c609d9d-2117-48cb-bdb6-a9938e5f4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracked2['track'].unique()\n",
    "disps = list()\n",
    "for track in tracks:\n",
    "    t = get_group(tracked1, 'track', track)\n",
    "    if len(t) <= 10: continue\n",
    "    d = np.diff(t[['x_um', 'y_um', 'z_um']].values, axis=0)\n",
    "    z = np.cumsum(np.sum(np.abs(d), axis=1))\n",
    "    disps.append(z)\n",
    "\n",
    "disp_lens = [len(disp) for disp in disps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7cfbf2-2787-45e2-8173-d63397a25459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 13))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "indexes = np.argsort(disp_lens)[:-1]\n",
    "n = len(indexes)\n",
    "for index in indexes:\n",
    "    xs = disps[index]\n",
    "    ys = disp_lens[index] * np.ones_like(xs) / n\n",
    "    zs = np.arange(len(xs))\n",
    "    \n",
    "    ax.plot(xs, ys, zs, linestyle='-', alpha=0.25)\n",
    "    ax.set_xlabel(u\"3D displacement ($\\mu$m)\")\n",
    "    ax.set_ylabel(u\"fraction of traces\")\n",
    "    ax.set_zlabel(u\"frames (#)\")\n",
    "\n",
    "ax.view_init(elev=30, azim=-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71323c8c-861a-4475-ad5b-5d53cd2a539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate step size statistics\n",
    "steps = dict.fromkeys(channels)\n",
    "for channel, df in zip(channels, (tracked1, tracked2)):\n",
    "    disps = tp.motion.relate_frames(df.rename(columns={'t' : 'frame', 'track' : 'particle'}), 0, 1, \\\n",
    "                                    pos_columns=['x_um', 'y_um', 'z_um'])[['dx_um', 'dy_um', 'dz_um']].dropna()\n",
    "    steps[channel] = np.abs(disps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5101da1-5ccf-43f7-a172-7fdb943e3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "for index, channel in enumerate(channels):\n",
    "    ax = axs[index]\n",
    "    for axis, color in zip(\n",
    "        ('dx_um', 'dy_um', 'dz_um'),\n",
    "        ('brown', 'crimson', 'orange'),\n",
    "    ):\n",
    "        ax.hist(steps[channel][axis], density=True, color=color, histtype='step', label=axis, linewidth=1.5)\n",
    "        ax.set_xlabel('inter-frame displacement ($\\mu$m)')\n",
    "        ax.set_ylabel('probability density')\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.legend()\n",
    "        ax.set_title(channel)\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef1f48-43d0-467f-98b3-5f427551d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for index, channel in enumerate(channels):\n",
    "    ax.hist(steps[channel].mean(axis=1), density=True, color=colors[channel], alpha=0.5)\n",
    "    ax.set_xlabel('inter-frame displacement ($\\mu$m)')\n",
    "    ax.set_ylabel('probability density')\n",
    "    ax.set_xlim(0, 25)\n",
    "ax.legend(channels)\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792b7e0-3bff-4f2a-b7be-affe223a52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = 'x_um', 'y_um', 'z_um'\n",
    "for channel, df in zip(channels, (tracked1, tracked2)):\n",
    "    print(channel, {axis : round(df[axis].max() - df[axis].min()) for axis in axes})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e1328-9a97-454b-9fd9-b61df00cc2ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.4 Conversion statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36acb5-266f-47ca-9678-f2b36ed311c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'x' : 'convert_len', 'bins' : np.arange(-0.5, 15, 1), 'fill' : True, 'stat' : 'density', 'cumulative' : False}\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "data = conversions.drop_duplicates(subset='track_Lamp1')\n",
    "data = data[data['conversion']]\n",
    "data['convert_len'] = data['overlap_stop'] - data['overlap_start']\n",
    "sns.histplot(ax=ax, data=data, **params, color='teal')\n",
    "ax.set_xlim(0, 15)\n",
    "ax.set_ylim(0, 0.8)\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0388af-df2e-469f-9a85-b19e1aeeef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'x' : 'convert_len', 'bins' : np.arange(-0.5, 15, 1), 'fill' : True, 'stat' : 'count', 'cumulative' : False}\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(ax=ax, data=data, **params, color='cornflowerblue')\n",
    "ax.set_xlim(0, 15)\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c025223-0638-4ad5-8f19-586dbe14d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_frames(conversion, trajectory):\n",
    "    track_start, track_stop = min(trajectory[channel1]['frame']), max(trajectory[channel2]['frame'])\n",
    "    convert_start, convert_stop = tuple(conversion.iloc[0][['convert_start', 'convert_stop']])\n",
    "    \n",
    "    before = int(convert_start - track_start)\n",
    "    during = int(convert_stop + 1 - convert_start)\n",
    "    after = int(track_stop - convert_stop)\n",
    "    total = int(track_stop + 1 - track_start)\n",
    "    \n",
    "    return {'before' : before, 'during' : during, 'after' : after, 'total' : total}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81829c-bc60-4693-bed5-e93a4ad76984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(conversions, collisions, trackA):\n",
    "    conversion = get_group(conversions, 'track', trackA)\n",
    "    collisionA = get_group(collisions[channel1], 'track', trackA)\n",
    "    trackE = conversion['collide_track'][conversion['frame'] == conversion['convert_stop']].iloc[-1]\n",
    "    collisionE = get_group(collisions[channel2], 'track', trackE)\n",
    "    return {channel1 : collisionA, channel2 : collisionE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003653a1-eabd-4a1c-91fc-0be9ceb7ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "frames = np.sort(collisions['frame'].unique())\n",
    "sns.scatterplot(ax=ax, data=data, x='overlap_start', y='convert_len', alpha=0.05, color='crimson', label='convert_start')\n",
    "sns.scatterplot(ax=ax, data=data, x='overlap_stop', y='convert_len', alpha=0.05, color='orange', label='convert_stop')\n",
    "ax.set_xlim(min(frames), max(frames))\n",
    "ax.set_ylim(0, 50)\n",
    "ax.legend()\n",
    "fig.tight_layout(pad=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df178a63-89b4-422d-b1ac-f790febe443c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4 Filter dataset by relative timing of events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e7a79-30b9-4314-8909-7c1af24bed74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.1 Create event-based filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72d5c4-cf2b-400f-a975-08da84998949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filters from buckets\n",
    "filters = buckets[buckets.columns[4:]]\n",
    "filters.sum() / len(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14864368-9535-4d6c-9623-f562dab3b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap to visualize fractions that passed each filter\n",
    "heatmap = pd.DataFrame(data=0, index=filters.columns, columns=filters.columns)\n",
    "for row, col in itertools.product(heatmap.columns, heatmap.columns):\n",
    "    heatmap.at[row, col] = sum(filters[row] & filters[col])\n",
    "\n",
    "# Visualize the heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "cmap = LinearSegmentedColormap.from_list('custom', [(0, white), (0.25, gray), (0.5, gold), (0.75, magenta), (1, black)])\n",
    "sns.heatmap(heatmap / len(buckets), annot=True, cmap=cmap, fmt='0.2f', linewidths=2, square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb887f86-9476-451f-a466-9c6079bb0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code to display decision tree in flowchart.js\n",
    "df0 = copy.deepcopy(filters)\n",
    "df1 = df0[df0['tracked_during_'+channel1] & df0['tracked_during_'+channel2]]\n",
    "df2a = df1[df1['started_before_'+channel1]]\n",
    "df2b = df1[df1['continued_after_'+channel2]]\n",
    "df3 = df1[df1['started_before_'+channel1] & df1['continued_after_'+channel2]]\n",
    "df4a = df3[df3['stopped_during_'+channel1]]\n",
    "df4b = df3[df3['decrease_during_'+channel1]]\n",
    "df4c = df3[df3['increase_during_'+channel2]]\n",
    "df5 = df3[df3['stopped_during_'+channel1] & df3['decrease_during_'+channel1] & df3['increase_during_'+channel2]]\n",
    "df7 = df5[df5['started_during_'+channel2]]\n",
    "df8 = df7\n",
    "\n",
    "flowchart = f\"\"\"\n",
    "st1=>start: initial set of potential conversions\n",
    "N = {len(df1)} ({100*len(df1)/len(df1):0.1f}% of initial dataset)\n",
    "op2=>operation: {channel1} track started before cotracking\n",
    "N = {len(df2a)} ({100*len(df2a)/len(df1):0.1f}% of initial dataset)\n",
    "op3=>operation: {channel2} track continued after cotracking\n",
    "N = {len(df2b)} ({100*len(df2b)/len(df1):0.1f}% of initial dataset)\n",
    "op3=>operation: {channel2} track continued after cotracking\n",
    "N = {len(df3)} ({100*len(df3)/len(df1):0.1f}% of initial dataset)\n",
    "op4=>operation: {channel1} track stopped during cotracking\n",
    "N = {len(df4a)} ({100*len(df4a)/len(df3):0.1f}% of filtered dataset)\n",
    "op5=>operation: {channel1} intensity decreased during cotracking\n",
    "N = {len(df4b)} ({100*len(df4b)/len(df3):0.1f}% of filtered dataset)\n",
    "op6=>operation: {channel2} intensity increased during cotracking\n",
    "N = {len(df4c)} ({100*len(df4c)/len(df3):0.1f}% of filtered dataset)\n",
    "op6=>operation: {channel2} intensity increased during cotracking\n",
    "N = {len(df5)} ({100*len(df5)/len(df3):0.1f}% of filtered dataset)\n",
    "cond=>condition: filter out fusions\n",
    "op7=>operation: {channel2} track started during cotracking\n",
    "N = {len(df7)} ({100*len(df7)/len(df5):0.1f}% of previous step)\n",
    "en1=>end: final set of filtered conversions\n",
    "N = {len(df5)} ({100*len(df5)/len(df1):0.1f}% of initial dataset)\n",
    "en2=>end: final set of filtered conversions\n",
    "N = {len(df8)} ({100*len(df8)/len(df1):0.1f}% of initial dataset)\n",
    "\n",
    "st1->op2\n",
    "op2->op3\n",
    "op3->op4\n",
    "op4->op5\n",
    "op5->op6\n",
    "op6->cond\n",
    "cond(no)->en1\n",
    "cond(yes)->op7\n",
    "op7->en2\n",
    "\"\"\"\n",
    "print(\"http://flowchart.js.org/\")\n",
    "print(flowchart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63abbe5-2c59-4538-932c-908cf77a6458",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.2 Filter data based on provided criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9f2ef-7f36-49e2-bf54-643325b59041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any lines not to be filtered on\n",
    "keep = (\n",
    "    buckets['tracked_during_'+channel1] & \n",
    "    buckets['tracked_during_'+channel2] &\n",
    "    buckets['decrease_during_'+channel1] & \n",
    "    buckets['increase_during_'+channel2] & \n",
    "    buckets['started_before_'+channel1] & \n",
    "    buckets['stopped_during_'+channel1] & \n",
    "    buckets['continued_after_'+channel2]\n",
    ")\n",
    "\n",
    "tracks1, tracks2, movies = zip(*buckets[keep][id_columns].drop_duplicates().values)\n",
    "ids_keep = tracks1, tracks2, movies\n",
    "print(f\"There are {len(tracks1)} tracks remaining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82228370-2dcc-4c22-b2cc-d5eb4d75bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down datasets according to filter criteria\n",
    "data1 = data1[data1['track_'+channel1].isin(tracks1) & data1['movie'].isin(movies)]\n",
    "data2 = data2[data2['track_'+channel2].isin(tracks2) & data2['movie'].isin(movies)]\n",
    "\n",
    "# The following line should evaluate to True\n",
    "all(data2 == data2.query(f\"event in {list(buckets['event'].values)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04831c0-f729-434c-9678-cb191e93503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter conversions by same criteria\n",
    "conversions2 = list()\n",
    "for track1, track2, movie in tqdm(zip(*ids_keep), total=len(tracks1)):\n",
    "    conversions2.append(conversions.groupby(['track_'+channel1, 'track_'+channel2, 'movie']).get_group((track1, track2, movie)))\n",
    "conversions2 = pd.concat(conversions2, ignore_index=True)\n",
    "\n",
    "# Sort and drop duplicates\n",
    "conversions2 = conversions2.sort_values(by='overlap_start')\n",
    "conversions2.drop_duplicates(subset=['track_'+channel1, 'movie'], ignore_index=True, inplace=True, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a09d2d-91ee-4e4b-b7fb-ba4c4a3000fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate tracks and movies\n",
    "tracks1, tracks2, movies = map(np.asarray, zip(*conversions2[id_columns].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0ae75-3275-4f0b-b6e8-6f443ba56696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all collisions also classified as cotracking events\n",
    "collisions2 = collisions.drop_duplicates(ignore_index=True)\n",
    "collisions2 = collisions2[collisions2['movie'].isin(set(np.unique(movies)))]\n",
    "cotrackings = conversions[conversions['movie'].isin(set(np.unique(movies)))]\n",
    "for _, row in tqdm(cotrackings.iterrows(), total=len(cotrackings)):\n",
    "    track1, track2, movie = row[id_columns]\n",
    "    frame1, frame2 = row[['overlap_start', 'overlap_stop']]\n",
    "    try:\n",
    "        df12 = collisions2.groupby(id_columns).get_group((track1, track2, movie))\n",
    "    except KeyError:\n",
    "        continue\n",
    "    ma12 = df12[df12['frame'].map(lambda frame: (frame >= frame1) and (frame <= frame2))].index\n",
    "    collisions2.drop(ma12, inplace=True)\n",
    "collisions2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"{len(collisions2)} remaining ({100 * len(collisions2) / len(collisions):0.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924b637-4c80-4ae4-8600-7f26da52d0b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.3 Save intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bb10d-79f1-451f-bea8-2de67f6ce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered results to file\n",
    "datasets['Filter2'] = {\n",
    "    'tracks1' : tracks1,\n",
    "    'tracks2' : tracks2,\n",
    "    'movies' : movies,\n",
    "    'tracked1' : tracked1,\n",
    "    'tracked2' : tracked2,\n",
    "    'collisions' : collisions2,\n",
    "    'conversions' : conversions2,\n",
    "    'buckets': buckets,\n",
    "    'data1' : data1,\n",
    "    'data2' : data2,\n",
    "}\n",
    "\n",
    "with open(csv_name, 'wb') as f:\n",
    "    f.write(pickle.dumps(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56701ecc-7a19-4ddd-bbb5-3b4842a3365a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.4 View individual time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba72b2f-9caa-4b25-b982-de3ec8091e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate all trajectories for visualization\n",
    "meaned = True\n",
    "normed = True\n",
    "\n",
    "signals = dict.fromkeys(channels)\n",
    "for channel, data in zip(channels, (data1, data2)):\n",
    "    for (movie, event), grouped in data.groupby(['movie', 'event']):\n",
    "        if 0 not in grouped['frame'].values:\n",
    "            continue\n",
    "        \n",
    "        ints = grouped.filter(like='signal')\n",
    "        if meaned:\n",
    "            ints = ints.div(grouped['V_um'].values, axis=0)\n",
    "        if normed:\n",
    "            ints = ints.div(ints[(grouped['frame'] == 0)].values, axis=1)\n",
    "        grouped[ints.columns] = ints\n",
    "        \n",
    "        signals[channel] = pd.concat([signals[channel], grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ff003-834c-476c-b7a3-a83d00bc741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_type = 'sub'\n",
    "min_length = 0\n",
    "max_length = 250\n",
    "\n",
    "fig, axss = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for axs, c1 in zip(axss, channels):\n",
    "    data = copy.deepcopy(signals[c1])\n",
    "    data = data[(data['length'] >= min_length) & (data['length'] < max_length)]\n",
    "    for (movie, event), df in data.groupby(['movie', 'event']):\n",
    "        for ax, c2 in zip(axs, channels):\n",
    "            columns = ['time', 'signal_' + int_type + '_' + c2]\n",
    "            x, y = map(np.asarray, zip(*df.sort_values(by='time')[columns].values))\n",
    "            \n",
    "            if len(x) < min_length:\n",
    "                continue\n",
    "            \n",
    "            if normed and np.any(np.abs(y) > 2.5):\n",
    "                continue\n",
    "            \n",
    "            ax.plot(x, y, alpha=0.01, color=colors[c2])\n",
    "\n",
    "for axs, c1 in zip(axss, channels):\n",
    "    for ax, c2 in zip(axs, channels):\n",
    "        ax.set_xlim(-40, +40)\n",
    "        if normed:\n",
    "            ylim = 0, 3\n",
    "        else:\n",
    "            if c2 == channel1:\n",
    "                ylim = 0, 25000\n",
    "            else:\n",
    "                ylim = 0, 50000\n",
    "            if c1 == channel2:\n",
    "                ylim = ylim[0], ylim[1] * 2\n",
    "        ax.set_ylim(*ylim)    \n",
    "        ax.set_xlabel('Time from Start of Cotracking (s)')\n",
    "        ax.set_ylabel('Intensity')\n",
    "        ax.set_title(f\"{c1} tracking, {c2} detection\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84091a22-cd7f-4172-bd14-b27a9a526d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results of Savitsky-Golay filter\n",
    "fig, ax = plt.subplots(figsize=(5, 2))\n",
    "ax.plot(x, y, cyan, label='raw data')\n",
    "ax.plot(x, signal.savgol_filter(y, 3, 1), magenta, label='smoothed')\n",
    "ax.set_xlabel('Time from Start of Cotracking (s)')\n",
    "ax.set_ylabel('Intensity')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059447f-5827-44a3-8068-5e4c503b213b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5 Filter collisions from cotracking events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c11f2-6ebf-4353-bb07-d08e94aef7d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5.1 Load intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000afd81-a913-4a60-b989-b4769a558868",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_name, 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Gather all data into a dict\n",
    "channel1, channel2 = channels = datasets['Metadata']['channels']\n",
    "colors = datasets['Metadata']['colors']\n",
    "movie_list = datasets['Metadata']['movie_list']\n",
    "frame_rates = datasets['Metadata']['frame_rates']\n",
    "\n",
    "tracks1 = copy.deepcopy(datasets['Filter2']['tracks1'])\n",
    "tracks2 = copy.deepcopy(datasets['Filter2']['tracks2'])\n",
    "movies = copy.deepcopy(datasets['Filter2']['movies'])\n",
    "\n",
    "tracked1 = copy.deepcopy(datasets['Filter2']['tracked1'])\n",
    "tracked2 = copy.deepcopy(datasets['Filter2']['tracked2'])\n",
    "collisions2 = copy.deepcopy(datasets['Filter2']['collisions'])\n",
    "conversions2 = copy.deepcopy(datasets['Filter2']['conversions'])\n",
    "\n",
    "buckets = copy.deepcopy(datasets['Filter2']['buckets'])\n",
    "data1 = copy.deepcopy(datasets['Filter2']['data1'])\n",
    "data2 = copy.deepcopy(datasets['Filter2']['data2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a3a9f-b5e1-487d-9761-0a03b0e18e23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5.2 Set thresholds of furthest distance for collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9cd4b-3472-4215-8307-e5cf8259efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save various pieces of collision data based on points of furthest distance,\n",
    "# to remove any particles that may be cotracking and not actually colliding\n",
    "collisions3_dict = dict()\n",
    "\n",
    "# For references, store unfiltered data\n",
    "collisions3_dict[0] = collisions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490427a-5d40-42bc-8705-83a9a9482293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all collisions where EEA1 does not spend time away from APPL1\n",
    "@dask.delayed\n",
    "def filter_by_furthest_distance(row, tracked1, tracked2, threshold=1.0):\n",
    "    track1, track2, movie = row[1][id_columns]\n",
    "    \n",
    "    # Get groups of colliding tracks\n",
    "    df1 = (tracked1\n",
    "           .groupby(['track', 'movie'])\n",
    "           .get_group((track1, movie))\n",
    "           .set_index('frame')\n",
    "           .filter(like='_um')\n",
    "          )\n",
    "    df2 = (tracked2\n",
    "           .groupby(['track', 'movie'])\n",
    "           .get_group((track2, movie))\n",
    "           .set_index('frame')\n",
    "           .filter(like='_um')\n",
    "          )\n",
    "    \n",
    "    # Reindex channel-specific dataframes to match\n",
    "    index12 = df1.index.intersection(df2.index)\n",
    "    df1 = df1.reindex(index12)\n",
    "    df2 = df2.reindex(index12)\n",
    "\n",
    "    # Get absolute positions in each channel\n",
    "    pos1 = df1[['z_um', 'y_um', 'x_um']]\n",
    "    pos2 = df2[['z_um', 'y_um', 'x_um']]\n",
    "    \n",
    "    # Get particle size (radius) in each channel\n",
    "    rad1 = df1['r_um']\n",
    "    rad2 = df2['r_um']\n",
    "    \n",
    "    # Calculate Euclidean distance between centroids\n",
    "    com_dist = (pos1 - pos2).apply(np.linalg.norm, axis=1)\n",
    "    \n",
    "    # Calculate distance between surfaces\n",
    "    surf_dist = com_dist - (rad1 + rad2)\n",
    "    \n",
    "    result = row[0]\n",
    "    for value in surf_dist.values:\n",
    "        if value > threshold:\n",
    "            result = None\n",
    "            break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be48cc7-798c-4ab3-906a-b76c49b09094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for detection of collisions based on furthest distance (microns)\n",
    "thresholds = 0.25, 0.5, 1.0\n",
    "\n",
    "for threshold in thresholds:\n",
    "# Execute the tasks in parallel\n",
    "    args = tracked1, tracked2\n",
    "    kwargs = dict(threshold=threshold)\n",
    "    tasks = [filter_by_furthest_distance(row, *args, **kwargs) for row in collisions.iterrows()]\n",
    "    with ProgressBar():\n",
    "        row_indexes = [result for result in dask.compute(*tasks) if result is not None]\n",
    "\n",
    "    # Remove all collisions where EEA1 does not spend time away from APPL1\n",
    "    collisions3 = collisions.drop(row_indexes).reset_index(drop=True)\n",
    "    collisions3_dict[threshold] = collisions3\n",
    "    print(f\"{threshold}: {len(collisions3)} remaining ({100 * len(collisions3) / len(collisions):0.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e74ff6-28b4-43a9-b3fb-434e7fe3255f",
   "metadata": {},
   "source": [
    "## 5.3 Save intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033ef29-92be-43c2-9b25-34ec81338228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered results to file\n",
    "datasets['Filter3'] = {\n",
    "    'collisions_dict' : collisions3_dict,\n",
    "}\n",
    "\n",
    "with open(csv_name, 'wb') as f:\n",
    "    f.write(pickle.dumps(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf8a85-2854-4825-a641-9cff803260d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 6 Filter collisions from near misses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173d637-27ef-4637-a3a5-71bf2d9f92a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6.1 Load intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c395f5-cf84-4890-9a8f-8df828e2958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_name, 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Gather all data into a dict\n",
    "channel1, channel2 = channels = datasets['Metadata']['channels']\n",
    "colors = datasets['Metadata']['colors']\n",
    "movie_list = datasets['Metadata']['movie_list']\n",
    "frame_rates = datasets['Metadata']['frame_rates']\n",
    "\n",
    "tracks1 = copy.deepcopy(datasets['Filter2']['tracks1'])\n",
    "tracks2 = copy.deepcopy(datasets['Filter2']['tracks2'])\n",
    "movies = copy.deepcopy(datasets['Filter2']['movies'])\n",
    "\n",
    "tracked1 = copy.deepcopy(datasets['Filter2']['tracked1'])\n",
    "tracked2 = copy.deepcopy(datasets['Filter2']['tracked2'])\n",
    "collisions2 = copy.deepcopy(datasets['Filter2']['collisions'])\n",
    "conversions2 = copy.deepcopy(datasets['Filter2']['conversions'])\n",
    "\n",
    "buckets = copy.deepcopy(datasets['Filter2']['buckets'])\n",
    "data1 = copy.deepcopy(datasets['Filter2']['data1'])\n",
    "data2 = copy.deepcopy(datasets['Filter2']['data2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31cd38-84ab-4e84-9030-db3b0e94bfaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6.2 Set thresholds of furthest distance for collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e704c-be68-418c-b824-887a8abe8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any collisions where endosomes separater by greater than maximum distance\n",
    "def collisions4_func(threshold):\n",
    "    collisions = copy.deepcopy(datasets['Filter1']['collisions'])\n",
    "    return collisions[collisions['surf_dist'] < threshold]\n",
    "\n",
    "for threshold in np.arange(-0.4, +0.4, 0.1):\n",
    "    # Remove all collisions where EEA1 and APPl1 are not close enough\n",
    "    collisions4 = collisions4_func(threshold)\n",
    "    print(f\"{threshold:+0.1f}: {len(collisions4)} remaining ({100 * len(collisions4) / len(collisions):0.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e1367-bceb-493a-907d-424e66de074f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6.3 Remove cases where EEA1 may be larger than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b765c-ff0a-482b-9d3e-ee350314a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge collisions data with size data for APPL1\n",
    "collisions5 = copy.deepcopy(datasets['Filter1']['collisions'])\n",
    "collisions5 = (\n",
    "    pd.merge(collisions5, tracked1[['r_um', 'track']], \n",
    "             left_on='track_APPL1', right_on='track',\n",
    "            )\n",
    "    .drop('track', axis=1)\n",
    "    .rename(columns={'r_um' : 'r_um_APPL1'})\n",
    "    .drop_duplicates(['frame', 'track_APPL1', 'track_Lamp1'], ignore_index=True)\n",
    ")\n",
    "\n",
    "# Merge collisions data with size data for EEA1\n",
    "collisions5 = (\n",
    "    pd.merge(collisions5, tracked2[['r_um', 'track']], \n",
    "             left_on='track_Lamp1', right_on='track',\n",
    "            )\n",
    "    .drop('track', axis=1)\n",
    "    .rename(columns={'r_um' : 'r_um_Lamp1'})\n",
    "    .drop_duplicates(['frame', 'track_APPL1', 'track_Lamp1'], ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72c103-8ddc-4e43-a12c-6bbb9a65e62c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6.4 Save intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c760d2d-aba4-4d90-8fbf-d7e909d3a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered results to file\n",
    "datasets['Filter3'] = {\n",
    "    'collisions_dict' : collisions3_dict,\n",
    "    'collisions_func' : collisions4_func,\n",
    "    'collisions' : collisions5,\n",
    "}\n",
    "\n",
    "with open(csv_name, 'wb') as f:\n",
    "    f.write(pickle.dumps(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca0737-679a-4ba6-8ad1-e57afc2c2bee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 7 Compare intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8141d-10b8-4d6c-b075-cab54dfb5fb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7.1 Load intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7dcc34-b19d-44e0-9389-423ca98235a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(csv_name, 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Gather all data into a dict\n",
    "channel1, channel2 = channels = datasets['Metadata']['channels']\n",
    "colors = datasets['Metadata']['colors']\n",
    "movie_list = datasets['Metadata']['movie_list']\n",
    "frame_rates = datasets['Metadata']['frame_rates']\n",
    "\n",
    "tracks1 = copy.deepcopy(datasets['Filter2']['tracks1'])\n",
    "tracks2 = copy.deepcopy(datasets['Filter2']['tracks2'])\n",
    "movies = copy.deepcopy(datasets['Filter2']['movies'])\n",
    "\n",
    "tracked1 = copy.deepcopy(datasets['Filter2']['tracked1'])\n",
    "tracked2 = copy.deepcopy(datasets['Filter2']['tracked2'])\n",
    "conversions2 = copy.deepcopy(datasets['Filter2']['conversions'])\n",
    "collisions2 = copy.deepcopy(datasets['Filter2']['collisions'])\n",
    "conversions3 = copy.deepcopy(datasets['Filter3']['collisions_dict'][1.0])\n",
    "\n",
    "buckets = copy.deepcopy(datasets['Filter2']['buckets'])\n",
    "data1 = copy.deepcopy(datasets['Filter2']['data1'])\n",
    "data2 = copy.deepcopy(datasets['Filter2']['data2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed5936-7b40-4fd9-b860-c7fb94861097",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7.2 Compare size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a18c1-6933-4bc4-bd2f-95a38a589689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tracked1['r_um'].values, tracked2['r_um'].values]\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    data[i] = d[(d > d.min()) & (d < d.max())]\n",
    "    display(Markdown((f\"$\\mu[{channels[i]}] = {np.mean(d):0.2f} \\pm {np.std(d):0.2f} \\mu$m\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f546-f174-4a41-bace-1e978cdee4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(4, 2.5))\n",
    "\n",
    "params = dict(data=data, ax=ax, alpha=0.5, palette=(cyan, magenta), stat='probability', shrink=3)\n",
    "h = sns.histplot(**params)\n",
    "ax.set_xlim(0.15, 0.75)\n",
    "ax.set_xlabel(u\"Radius ($\\mu$m)\")\n",
    "for t, l in zip(h.legend_.texts, (channel1, channel2)):\n",
    "    t.set_text(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc572b-2f3b-4cae-b009-c11390a9522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, channel in enumerate(channels):\n",
    "    df = pd.DataFrame(data[index], columns=[channel])\n",
    "    export_csv(df, f\"Size_{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bc5fb-c2d0-46d5-8269-18b08f5a0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_adjust = 5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "params = dict(ax=ax, bw_adjust=bw_adjust, palette=(magenta, cyan))\n",
    "sns.kdeplot(data=data[::-1], **params)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel(u\"Radius ($\\mu$m)\")\n",
    "ax.legend(labels=(channel1, channel2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2cf16c-3526-41fa-8e39-fd226121a7b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7.3 Comparize collision distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c116028-74a8-4ab8-9430-fa4ed336687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collisions2['surf_dist'].values, collisions3['surf_dist'].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "params = dict(data=data, ax=ax, palette=(gray, gold))\n",
    "sns.histplot(**params)\n",
    "ax.set_xlim(-1, 0.2)\n",
    "ax.set_xlabel(u\"Distance ($\\mu$m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402b31c-9fc9-46ce-b324-fcd2c0b45938",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_adjust = 1\n",
    "cut = 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "params = dict(ax=ax, bw_adjust=bw_adjust, cut=cut, palette=(gray, gold))\n",
    "sns.kdeplot(data=data, **params)\n",
    "\n",
    "ax.set_xlim(-0.9, 0.1)\n",
    "ax.set_xlabel(u\"Distance ($\\mu$m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c222d-c168-4579-a18d-2661e08600c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 8. Visualize final results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a23d3e-b70f-46c3-8c95-e19cd982c013",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.1 Load intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2d0d8-d5dd-40b5-8bc3-8c00b60c3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proper CSV name (latest export by default)\n",
    "datapaths = dict()\n",
    "for path in glob.glob('Dataset*.csv'):\n",
    "    match = re.match(r'^Dataset_(.*).csv$', path)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        datapaths[name] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edcf2f-a137-40b8-b46a-69adf8b72f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all datasets\n",
    "datasets = dict()\n",
    "for name, path in datapaths.items():\n",
    "    with open(path, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    datasets[name] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b7c30-0af5-42a3-916f-0e2cd08a70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(datasets.keys())\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b2b63-5b61-4689-ad25-ebb37eabcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = names[0]\n",
    "dataset = datasets[name]\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab835d-6c46-48e8-85a6-c8f51566a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all data into a dict\n",
    "channel1, channel2 = channels = dataset['Metadata']['channels']\n",
    "colors = dataset['Metadata']['colors']\n",
    "movie_list = dataset['Metadata']['movie_list']\n",
    "frame_rates = dataset['Metadata']['frame_rates']\n",
    "\n",
    "# Set ID and track columns\n",
    "track_columns = [f'track_{channel}' for channel in channels]\n",
    "id_columns = track_columns + ['movie']\n",
    "\n",
    "tracks1 = copy.deepcopy(dataset['Filter2']['tracks1'])\n",
    "tracks2 = copy.deepcopy(dataset['Filter2']['tracks2'])\n",
    "movies = copy.deepcopy(dataset['Filter2']['movies'])\n",
    "\n",
    "tracked1 = copy.deepcopy(dataset['Filter2']['tracked1'])\n",
    "tracked2 = copy.deepcopy(dataset['Filter2']['tracked2'])\n",
    "conversions = copy.deepcopy(dataset['Filter2']['conversions'])\n",
    "\n",
    "buckets = copy.deepcopy(dataset['Filter2']['buckets'])\n",
    "data1 = copy.deepcopy(dataset['Filter2']['data1'])\n",
    "data2 = copy.deepcopy(dataset['Filter2']['data2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831821c-2db6-40a9-bd9c-4ebe748ea546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.2 Set desired filters for collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ddd67-32e7-46c6-aca5-dc3b2e3bf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose specific value of furthest distance for collisions\n",
    "min_separation = 0.5\n",
    "max_separation = 0.2\n",
    "\n",
    "def collisions4_func(threshold):\n",
    "    collisions = copy.deepcopy(dataset['Filter1']['collisions'])\n",
    "    return collisions[collisions['surf_dist'] < threshold]\n",
    "\n",
    "collisions = pd.merge(\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            # Remove collisions identified as possible cotracking events\n",
    "            dataset['Filter2']['collisions'],\n",
    "            dataset['Filter3']['collisions'],\n",
    "        ),\n",
    "        # Remove collisions where greatest distance was not above threshold\n",
    "        dataset['Filter3']['collisions_dict'][min_separation],\n",
    "    ),\n",
    "    # Remove collisions where surfaces were not less than threshold\n",
    "    collisions4_func(max_separation),\n",
    ").drop_duplicates(['frame', 'track_APPL1', f'track_{channel2}'])\n",
    "\n",
    "# Remove collisions where EEA1 may have been larger than expected\n",
    "collisions = collisions[(collisions[f'r_um_{channel2}'] > tracked2['r_um'].min())]\n",
    "\n",
    "print(f\"min_separation={min_separation}, max_separation={max_separation}: {len(collisions)} remaining ({100 * len(collisions) / len(dataset['Filter1']['collisions']):0.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891c718-cca2-470f-aec9-118e368e3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(collisions), \n",
    " len(collisions) / len(tracked1.drop_duplicates(['movie', 'track'])),\n",
    " len(collisions.drop_duplicates(f'track_{channel1}')) / len(tracked1.drop_duplicates(['movie', 'track'])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ae780-751b-4d29-aebf-53350c4c251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV files for manuscript\n",
    "export_dir = f\"Exports_{name}_{today}\"\n",
    "os.path.exists(export_dir) or os.makedirs(export_dir)\n",
    "\n",
    "data1.to_csv(f\"{export_dir}{os.path.sep}Data_APPL1.csv\")\n",
    "data2.to_csv(f\"{export_dir}{os.path.sep}Data_EEA1.csv\")\n",
    "tracked1.to_csv(f\"{export_dir}{os.path.sep}Tracks_APPL1.csv\")\n",
    "tracked2.to_csv(f\"{export_dir}{os.path.sep}Tracks_EEA1.csv\")\n",
    "collisions.to_csv(f\"{export_dir}{os.path.sep}Collisions.csv\")\n",
    "conversions.to_csv(f\"{export_dir}{os.path.sep}Conversions.csv\")\n",
    "buckets.to_csv(f\"{export_dir}{os.path.sep}Buckets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7840-8e34-4519-94a0-fa9c3cb61b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(df:pd.DataFrame, filename:str, columns=[], dirname=\"\"):\n",
    "    if not dirname:\n",
    "        dirname = f\"Exports_{name}_{today}\"\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    if len(columns) == 0:\n",
    "        columns = df.columns\n",
    "    pathname = os.path.join(dirname, filename+'.csv')\n",
    "    df[columns].to_csv(pathname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346a631-78bd-43e5-acf2-d0db111e183b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.3 Separate fusions from conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dce49-9dc4-4efe-9562-b93e1e95bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fusion events\n",
    "fusions = list()\n",
    "for index, (track1, track2, movie) in tqdm(enumerate(zip(tracks1, tracks2, movies)), total=len(movies)):\n",
    "    conversion = conversions.groupby(id_columns).get_group((track1, track2, movie)).iloc[0]\n",
    "    start = conversion['overlap_start'] - conversion['track_'+channel2+'_start']\n",
    "    prior_failed_conversion = len(conversions.groupby(id_columns).get_group(tuple(conversion[id_columns])).query(f\"overlap_start < {conversion['overlap_start']}\")) > 1\n",
    "    if start < 1 or prior_failed_conversion:\n",
    "        case = 'convert'\n",
    "    else:\n",
    "        case = 'fusion'\n",
    "    case = 'convert' if start < 1 else 'fusion'\n",
    "    fusion = {f\"track_{channel1}\" : track1, f'track_{channel2}' : track2, 'start' : start, 'case' : case, 'movie' : movie}\n",
    "    fusions.append(fusion)\n",
    "fusions = pd.DataFrame(fusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545236a-f3bf-40d0-8e0d-ad66a1b7849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusions['case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3611f2-42fd-4619-bdfb-d9726296c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.ecdfplot(fusions['start'], ax=ax, stat='proportion')\n",
    "ax.set_xlabel(f\"Frames between Start of {channel2} Track and Start of Conversion\")\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57f58e-d814-419d-9534-0693d19cd66a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.4 Separate collisions from conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413f119-f86e-46a5-a506-b5d7bc5c97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frames_before = 8\n",
    "min_frames_around = 5\n",
    "\n",
    "df = list()\n",
    "n = -1\n",
    "u = 2\n",
    "cases = list()\n",
    "for track1, track2, movie in tqdm(zip(tracks1, tracks2, movies), total=len(tracks1)):\n",
    "    case = {'track_'+channel1 : track1, \n",
    "            'track_'+channel2 : track2, \n",
    "            'movie' : movie, 'case' : '', 'c2c' : 0}\n",
    "    \n",
    "    # Get relevant signal and collision data\n",
    "    datum1 = data1.groupby(['track_'+channel1, 'movie']).get_group((track1, movie)).sort_values(by='frame').drop_duplicates(subset='frame')\n",
    "    conversion = conversions.drop_duplicates().groupby(['track_'+channel1, 'movie']).get_group((track1, movie)).iloc[0]\n",
    "    \n",
    "    # Get frames for each event of interest\n",
    "    start_frame1 = conversion['track_'+channel1+'_start']\n",
    "    start_frame2 = conversion['track_'+channel2+'_start']\n",
    "    convert_frame = conversion['overlap_start']\n",
    "    \n",
    "    prior_failed_conversion = len(conversions.groupby(id_columns).get_group(tuple(conversion[id_columns])).query(f\"overlap_start < {conversion['overlap_start']}\")) > 1\n",
    "    \n",
    "    try:\n",
    "        collision = collisions.groupby(['track_'+channel1, 'movie']).get_group((track1, movie)).sort_values(by='frame')\n",
    "        collision = collision[collision['surf_dist'] <= 0.25]\n",
    "        #collision = collision[collision['surf_dist'] > -0.25]\n",
    "        \n",
    "        collide_frame = collision[collision['frame'] < convert_frame]['frame'].max()\n",
    "        \n",
    "        track3 = collision.groupby('frame').get_group(collide_frame).iloc[0]['track_'+channel2]\n",
    "        datum3 = tracked2.groupby(['track', 'movie']).get_group((track3, movie)).sort_values(by='frame').drop_duplicates(subset='frame')\n",
    "        \n",
    "    except (KeyError, ValueError):\n",
    "        collide_frame = np.nan\n",
    "        \n",
    "    if (convert_frame - start_frame1) < min_frames_before:\n",
    "        # APPL1 tracked for insufficient frames beforehand\n",
    "        case['case'] = f\"not enough data ({channel1})\"\n",
    "        case['c2c'] = np.nan\n",
    "    elif np.isnan(collide_frame):\n",
    "        if (convert_frame - start_frame2) <= 0 or prior_failed_conversion:\n",
    "            # Direct conversion means no collisions detected\n",
    "            case['case'] = 'conversion, unaided'\n",
    "        else:\n",
    "            # Direct fusion means no prior collisions detected\n",
    "            case['case'] = 'fusion, unaided'\n",
    "        case['c2c'] = 0\n",
    "    elif len(datum3) < min_frames_around:# and np.mean(datum3['signal_nrm_'+channel2]) > 5:\n",
    "        # Colliding EEA1 tracked for insufficient frames\n",
    "        case['case'] = f\"not enough data ({channel2})\"\n",
    "        case['c2c'] = np.nan\n",
    "    else:\n",
    "        if (convert_frame - start_frame2) <= 0 or prior_failed_conversion:\n",
    "            # Collision leading to conversion\n",
    "            case['case'] = 'conversion, collision-induced'\n",
    "        else:\n",
    "            # Collision leading to fusion\n",
    "            case['case'] = 'fusion, collision-induced'\n",
    "        case['c2c'] = convert_frame - collide_frame\n",
    "\n",
    "        # Save intensity traces for analysis of collisions cases\n",
    "        between = datum1[(datum1['frame'] >= (collide_frame - convert_frame)) & (datum1['frame'] <= 0)]\n",
    "        between = between[['frame', 'signal_sub_'+channel1, 'signal_sub_'+channel2]].drop_duplicates()\n",
    "\n",
    "        x, y1, y2 = np.transpose(between.values)\n",
    "        y1 = y1 / y1[n]\n",
    "        y2 = y2 / y2[n]\n",
    "\n",
    "        if all((-u < y1) & (y1 < u) & (-u < y2) & (y2 < u)):\n",
    "            df.append([{'frame' : x_, 'signal_'+channel1 : y1_, 'signal_'+channel2 : y2_, 'track_'+channel1: track1, 'movie': movie} for x_, y1_, y2_ in zip(x, y1, y2)])\n",
    "    cases.append(case)\n",
    "\n",
    "cases = pd.DataFrame(cases).sort_values(by='case')\n",
    "df = pd.DataFrame(itertools.chain(*df))\n",
    "df['time'] = df['frame'] * df['movie'].map(frame_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76c767-3e6f-4d36-9929-5c9f6c05f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2 = cases[cases['case'].map(lambda x: not x.startswith('not enough data'))]\n",
    "num_cases = len(cases2)\n",
    "print(num_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b14e33-db27-46b9-a7e0-f1d87e0df3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2['case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cf3e6-42a2-425c-8154-01f167c87b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.sort(cases2['case'].unique())\n",
    "markers = {label: ('s' if 'direct' in label else 'o') for label in labels}\n",
    "palette = cyan, gray, magenta, white\n",
    "\n",
    "def get_label(key):\n",
    "    if key in ('r_um', ):\n",
    "        label = key[0] + u\" ($\\mu$m)\"\n",
    "    elif key in ('V_um', ):\n",
    "        label = key[0] + u\" ($\\mu$m$^{3}$)\"\n",
    "    elif key in ('signal_nrm_'+channel1, 'signal_nrm_'+channel2):\n",
    "        label = key + u\" (%)\"\n",
    "    elif key in ('length', ):\n",
    "        label = key + u\" (frames)\"\n",
    "    else:\n",
    "        label = key\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b06997-639f-4ec3-8323-6a690908b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data1.groupby(id_columns)\n",
    "labels = np.sort(cases2['case'].unique())\n",
    "query = '(frame >= -4) & (frame < -0)'\n",
    "#query = '(frame >= 4) & (frame < 8)'\n",
    "results = list()\n",
    "for case in labels:\n",
    "    for _, row in cases2.query(f'case == \"{case}\"').iterrows():\n",
    "        track1, track2, movie = row[id_columns]\n",
    "        group = grouped.get_group((track1, track2, movie)).query(query)\n",
    "        if len(group) > 0:\n",
    "            values = dict(group.mean(axis=0))\n",
    "            #result = {'case': 'fusion' if 'fusion' in case else case, **values}\n",
    "            result = {'case': case, **values}\n",
    "            results.append(result)\n",
    "results = pd.DataFrame(results)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2869c5-6be7-41ca-baec-65e8162f6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['case'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53018a88-cde3-466b-bd58-2dea616d9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.deepcopy(results)\n",
    "data['case'].replace('conversion, unaided', ' unaided', inplace=True)\n",
    "data['case'].replace('conversion, collision-induced', ' collision-induced', inplace=True)\n",
    "data['case'].replace('fusion, unaided', '  unaided', inplace=True)\n",
    "data['case'].replace('fusion, collision-induced', '  collision-induced', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cc81e-e3c3-4a63-abb2-73f43e4c0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'r_um'\n",
    "#key = 'signal_sub_'+channel1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8*cm, 5*cm), dpi=150)\n",
    "params = dict(data=data, x=key, y='case', ax=ax)\n",
    "sns.boxplot(**params, palette=palette, saturation=1, whis=1)\n",
    "ax.set_xlabel(get_label(key))\n",
    "ax.set_ylabel(None)\n",
    "ax.set_title('conversions     fusions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ad9b9-bf2d-4b3a-a920-c91346d97c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv(data, 'SizeBeforeEvent', ['r_um', 'case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737a9a3-be46-41bb-9080-f247675d7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.query(\"case == 'conversion, unaided'\")['r_um'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090148d-69b6-4147-b3c6-b27450eb4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'signal_sub_'+channel1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "params = dict(data=results, x=key, y='case', ax=ax)\n",
    "sns.boxplot(**params, palette=palette, saturation=1, whis=1)\n",
    "sns.stripplot(**params, color='black')\n",
    "ax.set_xlabel(get_label(key))\n",
    "ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eeb2c3-6999-4c8a-b665-9ea4beea9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "x = 'signal_sub_'+channel1\n",
    "#x = 'r_um'\n",
    "y = 'length'\n",
    "hue = 'case'\n",
    "style = 'case'\n",
    "params = dict(data=results, x=x, y=y, alpha=0.8, hue=hue, ax=ax, markers=markers, style=style, palette=palette)\n",
    "\n",
    "sns.scatterplot(**params)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "ax.set_xlabel(get_label(x))\n",
    "ax.set_ylabel(get_label(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284ea60-bd43-4f0d-ad26-445c9c60b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cases['case'].value_counts())\n",
    "print()\n",
    "print(100 * cases2['case'].value_counts().div(num_cases).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef731e-31fc-4e08-ac92-0e0cfea934e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cases['case'].value_counts())\n",
    "print()\n",
    "print(100 * cases2['case'].value_counts().div(num_cases).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35790825-05e0-47c9-a982-fa5d39473be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.ecdfplot((cases['c2c'] * df['movie'].map(frame_rates)).dropna(), ax=ax, stat='proportion')\n",
    "ax.set_xlabel('Time between Collision and Start of Conversion (s)')\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8407d-704a-4630-9e63-abbf634901ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.5 Visualize intensity time traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cccf3fe-9a2a-4f30-ace2-676c1cb91c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 5))\n",
    "ax1, ax2 = np.ravel(axs)\n",
    "\n",
    "for _, g in df.groupby(['track_'+channel1, 'movie']):\n",
    "    x, y1, y2 = np.transpose(g[['time', 'signal_'+channel1, 'signal_'+channel2]].values)\n",
    "    \n",
    "    ax1.plot(x, y1, alpha=alpha, color=colors[channel1])\n",
    "    ax2.plot(x, y2, alpha=alpha, color=colors[channel2])\n",
    "    \n",
    "for ax, channel in zip((ax1, ax2), channels):\n",
    "    ax.set_xlim(-90, 0)\n",
    "    #ax.set_ylim(-1, 2)\n",
    "    ax.set_ylim(0, 2)\n",
    "    if ax == ax2:\n",
    "        ax.set_xlabel('Time Relative to Start of Conversion (s)')\n",
    "    ax.set_ylabel('Relative Intensity')\n",
    "    ax.set_title(channel)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc5b0b-7f62-4149-8c9a-237c7b64d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "  \n",
    "for channel in channels:\n",
    "    g = df.groupby('time')['signal_' + channel]\n",
    "    x, y = zip(*g.mean().items())\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        l, u = zip(*g.apply(get_ci).values)\n",
    "\n",
    "    ax.plot(x, y, color=colors[channel], label=channel)\n",
    "    \n",
    "for _, g in df.groupby(['track_'+channel1, 'movie']):\n",
    "    x, y1, y2 = np.transpose(g[['time', 'signal_'+channel1, 'signal_'+channel2]].values)\n",
    "    ax.plot(x, y1, alpha=alpha, color=colors[channel1])\n",
    "    ax.plot(x, y2, alpha=alpha, color=colors[channel2])\n",
    "    \n",
    "ax.set_xlim(-60, 0)\n",
    "#ax.set_ylim(-1.25, 2.25)\n",
    "ax.set_ylim(0, 2)\n",
    "ax.set_xlabel('Time Relative to Start of Conversion (s)')\n",
    "ax.set_ylabel('Relative Intensity')\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc4492-4d6d-4208-9812-7c00b3e9b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate all trajectories for visualization\n",
    "meaned = True\n",
    "normed = True\n",
    "\n",
    "signals = dict.fromkeys(channels)\n",
    "for channel, data in zip(channels, (data1, data2)):\n",
    "    for (movie, event), grouped in data.groupby(['movie', 'event']):\n",
    "        if 0 not in grouped['frame'].values:\n",
    "            continue\n",
    "        \n",
    "        ints = grouped.filter(like='signal')\n",
    "        if meaned:\n",
    "            ints = ints.div(grouped['V_um'].values, axis=0)\n",
    "        if normed:\n",
    "            ints = ints.div(ints[(grouped['frame'] == 0)].values, axis=1)\n",
    "        grouped[ints.columns] = ints\n",
    "        \n",
    "        signals[channel] = pd.concat([signals[channel], grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3106be-7702-4414-8bf1-75d6f26f0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_type = 'nrm'\n",
    "sig_columns = ['signal_' + int_type + '_' + c for c in channels]\n",
    "\n",
    "data = copy.deepcopy(signals[channel1].drop_duplicates(subset=['track_'+channel1, 'frame']))\n",
    "n1 = [len(group) for frame, group in data.groupby('frame')]\n",
    "t1 = [group['time'].iloc[0] for frame, group in data.groupby('frame')]\n",
    "\n",
    "data = copy.deepcopy(df.drop_duplicates(subset=['track_'+channel1, 'frame']))\n",
    "n2 = [len(group) for frame, group in data.groupby('frame')]\n",
    "t2 = [group['time'].iloc[0] for frame, group in data.groupby('frame')]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 2))\n",
    "ax.plot(t1, n1, color=cyan)\n",
    "ax.plot(t2, n2, color=magenta)\n",
    "ax.set_xlim(-60, 60)\n",
    "ax.set_xlabel('Time from Start of Cotracking (s)')\n",
    "ax.set_ylabel('Tracked Count (#)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d6917-3a6c-4d63-87aa-1e8d5862fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.99\n",
    "int_type = 'sub'\n",
    "min_time = 10\n",
    "max_time = min_time + 10\n",
    "# max_time = 60\n",
    "\n",
    "title = f\"{min_time} s < Conversion Time $\\leq$ {max_time} s\"\n",
    "sig_columns = ['signal_' + int_type + '_' + c for c in channels]\n",
    "\n",
    "t = list()\n",
    "M = list()\n",
    "S = list()\n",
    "L = list()\n",
    "U = list()\n",
    "n = list()\n",
    "\n",
    "tracks1, tracks2, movies = map(np.asarray, zip(*conversions[['track_'+channel1, 'track_'+channel2, 'movie']].values))\n",
    "grouped = {c : signals[c].groupby('frame') for c in channels}\n",
    "\n",
    "for frame in tqdm(range(-50, 50), total=100):\n",
    "    try:\n",
    "        groups = {c : grouped[c].get_group(frame) for c in channels}\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for track1, track2, movie in zip(tracks1, tracks2, movies):\n",
    "        groups2 = dict()\n",
    "        for c in channels:\n",
    "            try:\n",
    "                group2 = groups[c].groupby('movie').get_group(movie)\n",
    "            except KeyError:\n",
    "                group2 = pd.DataFrame(columns=groups[c].columns)\n",
    "            groups2[c] = group2\n",
    "        \n",
    "        frame_rate = frame_rates[movie]\n",
    "        min_frame = int(min_time // frame_rate)\n",
    "        max_frame = int(max_time // frame_rate)\n",
    "        \n",
    "        if frame <= max_frame and track1 in groups2[channel1]['track_'+channel1].values:\n",
    "            c1 = channel1\n",
    "            track = track1\n",
    "        elif track2 in groups2[channel2]['track_'+channel2].values:\n",
    "            c1 = channel2\n",
    "            track = track2\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        g = groups2[c1].groupby('track_' + c1).get_group(track)\n",
    "        if (g['length'].iloc[0] > min_frame) and (g['length'].iloc[0] <= max_frame):            \n",
    "            df = pd.concat((df, g.filter(like=int_type)))\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    df = df[(df > 0.25) & (df <= 4.0)].dropna().reset_index(drop=True)\n",
    "    \n",
    "    t.append(frame * frame_rate)\n",
    "    M.append(dict(df.mean()))\n",
    "    S.append(dict(df.std()))\n",
    "    n.append(len(df))\n",
    "\n",
    "    if frame != 0 and len(df) > 1:\n",
    "        l, u = np.transpose([get_ci(df[c2], confidence) for c2 in sig_columns])\n",
    "    else:\n",
    "        l = u = (np.nan, np.nan)\n",
    "\n",
    "    L.append(dict(zip(sig_columns, l)))\n",
    "    U.append(dict(zip(sig_columns, u)))\n",
    "\n",
    "t = np.asarray(t)\n",
    "n = np.asarray(n)\n",
    "\n",
    "M = pd.DataFrame(M)\n",
    "S = pd.DataFrame(S)\n",
    "L = pd.DataFrame(L)\n",
    "U = pd.DataFrame(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c209e1-3503-4c88-890d-c24aa004fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12*cm, 3*cm), dpi=150)\n",
    "\n",
    "for channel in channels:\n",
    "    column = 'signal_' + int_type + '_' + channel\n",
    "    m = M[column]\n",
    "    s = S[column]\n",
    "    l = L[column]\n",
    "    u = U[column]\n",
    "    \n",
    "    ax.axvline(0, color='k', alpha=0.5, ls='--', lw=1.0)\n",
    "    ax.axvline(min_time, color='gray', alpha=0.5, ls='--', lw=1.0)\n",
    "    ax.axvline(max_time, color='gray', alpha=0.5, ls='--', lw=1.0)\n",
    "    ax.axvspan(min_time, max_time, facecolor='gray', alpha=0.05)\n",
    "    \n",
    "    ax.plot(t, m, color=colors[channel], label=channel)\n",
    "    ax.fill_between(t, l, u, alpha=0.2, color=colors[channel])\n",
    "\n",
    "ax.set_xlim(-20, +60)\n",
    "ax.set_ylim(0.75, 1.45)\n",
    "ax.set_xlabel(u\"Time Relative to Start of Conversion (s)\")\n",
    "ax.set_ylabel(u\"Relative Intensity\")\n",
    "#ax.set_title(title)\n",
    "#ax.set_title('WT')\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35a4cf-a76a-43ab-a770-522227ededea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    **pd.DataFrame(t, columns=['time_rel']).to_dict(),\n",
    "    **M.rename(columns={'signal_sub_EEA1' : 'mean_EEA1', f'signal_sub_{channel1}' : f'mean_{channel1}'}),\n",
    "    **U.rename(columns={'signal_sub_EEA1' : 'upper_EEA1', f'signal_sub_{channel1}' : f'upper_{channel1}'}),\n",
    "    **L.rename(columns={'signal_sub_EEA1' : 'lower_EEA1', f'signal_sub_{channel1}' : f'lower_{channel1}'}),\n",
    "})\n",
    "\n",
    "export_csv(df.query(\"time_rel >= -22.5 and time_rel <= 62.5\"), f\"IntensityTrace_{min_time:d}-{max_time:d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8483b68-5ad2-4b90-82fd-9294df51ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ts\n",
    "except NameError:\n",
    "    ts = dict()\n",
    "    Ms = dict()\n",
    "    Ss = dict()\n",
    "    Ls = dict()\n",
    "    Us = dict()\n",
    "\n",
    "ts[min_frame] = t\n",
    "Ms[min_frame] = M\n",
    "Ss[min_frame] = S\n",
    "Ls[min_frame] = L\n",
    "Us[min_frame] = U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f3dfa-1e43-4491-90c9-7b78adc2fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(12*cm, 14*cm), dpi=150)\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax, channel in zip(axs, channels):\n",
    "    ax.axvline(0, color='k', alpha=0.5, ls='--', lw=1.0)\n",
    "    column = 'signal_' + int_type + '_' + channel\n",
    "    for min_frame, color in zip(Ms.keys(), (magenta, cyan, gray)):\n",
    "        t = ts[min_frame]#[indexes]\n",
    "        m = Ms[min_frame][column]#[indexes]\n",
    "        s = Ss[min_frame][column]#[indexes]\n",
    "        l = Ls[min_frame][column]#[indexes]\n",
    "        u = Us[min_frame][column]#[indexes]\n",
    "        \n",
    "        min_time = int(min_frame * frame_rate)\n",
    "        max_time = int(min_frame * frame_rate) + 10\n",
    "        en_dash = u\"\\u2013\"\n",
    "        label = f\"{min_time}{en_dash}{max_time} s\"\n",
    "        \n",
    "        ax.plot(t, m, color=color, label=label)\n",
    "        ax.fill_between(t, l, u, alpha=0.1, color=color)\n",
    "    \n",
    "    ax.set_xlim(-20, +60)\n",
    "    ax.set_ylim(0.7, 1.7)\n",
    "    ax.set_ylabel(u\"Relative Intensity\")\n",
    "    if ax == axs[1]:\n",
    "        ax.set_xlabel(u\"Time Relative to Start of Conversion (s)\")\n",
    "    ax.set_title(channel, {'fontweight' : 'medium'})\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91c215-6291-402f-b7b3-f31d858620b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.6 Compare across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec87771-4f12-40bf-863c-0a4a0dcfda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tC\n",
    "except NameError:\n",
    "    tC = dict()\n",
    "    MC = dict()\n",
    "    SC = dict()\n",
    "    LC = dict()\n",
    "    UC = dict()\n",
    "\n",
    "tC[condition] = t\n",
    "MC[condition] = M\n",
    "SC[condition] = S\n",
    "LC[condition] = L\n",
    "UC[condition] = U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df7b1f-46f4-408d-a9f6-6070b377b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(12*cm, 14*cm), dpi=150)\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax, condition in zip(axs, tC.keys()):\n",
    "    ax.axvline(0, color='k', alpha=0.5, ls='--', lw=1.0)\n",
    "    for channel, color in zip(channels, (cyan, magenta)):\n",
    "        column = 'signal_' + int_type + '_' + channel\n",
    "        \n",
    "        t = tC[condition]\n",
    "        m = MC[condition][column]\n",
    "        s = SC[condition][column]\n",
    "        l = LC[condition][column]\n",
    "        u = UC[condition][column]\n",
    "        \n",
    "        min_time = int(min_frame * frame_rate)\n",
    "        max_time = int(min_frame * frame_rate) + 10\n",
    "        en_dash = u\"\\u2013\"\n",
    "        label = f\"{min_time}{en_dash}{max_time} s\"\n",
    "        \n",
    "        ax.plot(t, m, color=color, label=channel)\n",
    "        ax.fill_between(t, l, u, alpha=0.1, color=color)\n",
    "    \n",
    "    ax.set_xlim(-20, +60)\n",
    "    ax.set_ylim(0.7, 1.7)\n",
    "    ax.set_ylabel(u\"Relative Intensity\")\n",
    "    if ax == axs[1]:\n",
    "        ax.set_xlabel(u\"Time Relative to Start of Conversion (s)\")\n",
    "    ax.set_title('WT' if condition == '_Senthil' else condition.lower(), {'fontweight' : 'medium'})\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2953a-e640-418d-baa4-aa7ab96607c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cases.dropna()['c2c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff44a6-7732-4835-b7a7-018c404ab385",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2 = cases.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97055b3-67e1-4446-afe9-f129a3d11420",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8.7 Create heatmap of collisions and conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59514179-a416-46f8-a508-5650b871f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_ = cases2[cases2['case'].map(lambda x: x.startswith('fusion'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c64297-5471-4d84-8cab-c296ab770a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = list()\n",
    "for index, row in tqdm(cases_.iterrows(), total=len(cases_.drop_duplicates())):\n",
    "    track1, track2, movie = row[['track_'+channel1, 'track_'+channel2, 'movie']]\n",
    "    \n",
    "    try:\n",
    "        # Get correct conversion event\n",
    "        conversion = (conversions[conversions['movie'] == movie]\n",
    "                      .query(f\"track_{channel1} == {track1} and track_{channel2} == {track2}\")\n",
    "                      .sort_values(by='overlap_stop')\n",
    "                      .drop_duplicates(keep='last')\n",
    "                     ).iloc[-1]\n",
    "        convert_start = conversion['overlap_start']\n",
    "\n",
    "        # Get number of collisions before start of conversion\n",
    "        collision = (collisions[collisions['movie'] == movie]\n",
    "                     .query(f\"track_{channel1} == {track1}\")\n",
    "                     .drop_duplicates()\n",
    "                    )\n",
    "        collision = collision[collision['frame'] <= convert_start]\n",
    "        collision = collision[collision['surf_dist'] <= 0.2]\n",
    "        num_collisions = len(collision)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        num_collisions = 0\n",
    "    \n",
    "    frames_before = conversion['overlap_start'] - conversion['track_'+channel1+'_start']\n",
    "    frames_during = conversion['overlap_stop'] - conversion['overlap_start']\n",
    "\n",
    "    data_.append({'num_collisions' : num_collisions,\n",
    "                  'frames_before' : frames_before,\n",
    "                  'frames_during' : frames_during,\n",
    "                  'time_before': frames_before * frame_rates[movie],\n",
    "                  'time_during' : frames_during * frame_rates[movie],\n",
    "                 })\n",
    "\n",
    "data_ = pd.DataFrame(data_).drop_duplicates()\n",
    "data_['num_collisions'].value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad2fcd-b31d-46d0-ab84-f0a3aeca7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set minimum time required before conversion to be analyzed\n",
    "min_time_before = 28\n",
    "data = data_[data_['time_before'] >= min_time_before]\n",
    "\n",
    "base = 10\n",
    "data['block_before'] = (data['time_before'] // base).astype(int)\n",
    "data['block_during'] = (data['time_during'] // base).astype(int)\n",
    "\n",
    "# Set minimum conversion length\n",
    "min_collisions = 0\n",
    "min_convert_len = 4 / base\n",
    "\n",
    "# Set maximum conversion length\n",
    "max_collisions = max(data['num_collisions'])\n",
    "max_convert_len = 135 / base\n",
    "\n",
    "# Create matrix to be used for generating heatmap\n",
    "mat = np.zeros((max(data['block_during']) + 1, max(data['num_collisions']) + 1), dtype=int)\n",
    "for (num_collision, block_during), count in data.groupby(['num_collisions', 'block_during']).size().items():\n",
    "    mat[block_during, num_collision] = count\n",
    "\n",
    "# Optionally remove cases of less-than minimum collisions\n",
    "mat[:, :min_collisions] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f4e1b-f036-4443-bb7c-29afb5e7377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = max(5 * (mat.max() // 5 + 1), 5)\n",
    "if N > 5:\n",
    "    cmap = LinearSegmentedColormap.from_list('custom', [(0, white), (0.2, gray), (0.3, cyan), (1, magenta)], N=N, gamma=1.0)\n",
    "else:\n",
    "    cmap = LinearSegmentedColormap.from_list('custom', [(0, white), (0.5, gray), (0.6, cyan), (1, magenta)], N=N, gamma=1.0)\n",
    "\n",
    "frame_rate = 2.5\n",
    "yticks = np.arange(0, max_convert_len) * base # frame_rate\n",
    "\n",
    "yticklabels = list()\n",
    "for ytick in yticks:\n",
    "    if np.mod(ytick, 1) == 0:\n",
    "        yticklabel = str(round(ytick))\n",
    "    else:\n",
    "        yticklabel = ''\n",
    "    yticklabels.append(yticklabel)\n",
    "\n",
    "xticklabels = [(str(v) if v % 1 == 0 else '') for v in range(100)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8*cm, 8*cm), dpi=150)\n",
    "sns.heatmap(mat, cmap=cmap, cbar=True, square=True, xticklabels=xticklabels, yticklabels=yticklabels, vmin=-0.5, vmax=N-0.5)\n",
    "ax.set_xlabel('Collisions before\\nConversion (#)')\n",
    "ax.set_ylabel('Conversion Duration (s)')\n",
    "ax.set_xlim(min_collisions, min_collisions + 6)\n",
    "ax.set_ylim(min_convert_len, max_convert_len - min_convert_len)\n",
    "\n",
    "ax.collections[0].set_clim(0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7e599-7fd4-447e-b9e6-608b288101ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mat[1:12, :])\n",
    "df /= df.sum().sum()\n",
    "export_csv(df, 'CollisionsToEvents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4af86-c44e-497d-ad54-847df9af5996",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 9 Check final analysis statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4047548-dc5e-4e75-9a18-90bc450cc0d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.1 Find all collisions leading to conversions and/or fusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5b489-e86e-445f-b14e-f65858373bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_separation = 0.25\n",
    "\n",
    "converted_indexes = list()\n",
    "for index, row in tqdm(cases2.iterrows(), total=len(cases2.drop_duplicates())):\n",
    "    track1, track2, movie = row[['track_'+channel1, 'track_'+channel2, 'movie']]\n",
    "    \n",
    "    try:\n",
    "        # Get correct conversion event\n",
    "        conversion = (conversions\n",
    "                      .query(f\"movie == {movie} and track_{channel1} == {track1} and track_EEA1 == {track2}\")\n",
    "                      .sort_values(by='overlap_stop')\n",
    "                      .drop_duplicates(keep='last')\n",
    "                     ).iloc[-1]\n",
    "        convert_start = conversion['overlap_start']\n",
    "\n",
    "        # Get indexes of collisions before start of conversion\n",
    "        collision = (collisions\n",
    "                     .query(f\"movie == {movie} and track_{channel1} == {track1}\")\n",
    "                     .drop_duplicates()\n",
    "                    )\n",
    "        collision = collision[(collision['frame'] < convert_start) & \n",
    "                              (collision['surf_dist'] < max_separation)]\n",
    "        collision = collision.sort_values('frame')\n",
    "        if len(collision)> 0:\n",
    "            converted_indexes.append(collision.index[-1])\n",
    "    except KeyError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85716c4e-0bd7-4bf0-b4f3-e5f9d9c9f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at collisions leading directly to conversions\n",
    "collisions_ = collisions.loc[converted_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8fe692-ad07-4310-bf96-3e928b5ba24e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.2 Calculate distribution of nearest-neighbor distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7819f77-a9aa-469a-9383-e35bceb3f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e20d76-ae93-40e9-825c-ff5958c621fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_columns = ['x_um', 'y_um', 'z_um']\n",
    "\n",
    "# Construct the KDTree\n",
    "def make_tree(df, columns=spatial_columns):\n",
    "    centroids = df[columns].values\n",
    "    tree = cKDTree(centroids)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc9019-a944-4e5f-a9c1-466fab927d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of tracked data for convenience\n",
    "data_dict = dict()\n",
    "for channel, df in zip(channels, (tracked1, tracked2)):\n",
    "    data = {(movie, frame) : group for (movie, frame), group in df.groupby(['movie', 'frame'])}\n",
    "    data_dict[channel] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8a04d-c2ac-47c6-a681-60ebc9feb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all combinations of movies and frames\n",
    "movie_frames = [v for v in data_dict[channel1].keys() if v in data_dict[channel2].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49e128-b914-4661-ae44-fe8585df1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KDTrees for each channel and timepoint\n",
    "trees_dict = dict()\n",
    "for channel, data in data_dict.items():\n",
    "    trees = {(movie, frame) : make_tree(group) for (movie, frame), group in data.items()}\n",
    "    trees_dict[channel] = trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04b446-854d-479e-a284-1a9501e3aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the KDTree for nearest neighbor distances (same species)\n",
    "cent_dists_dict = dict()\n",
    "for channel in channels:\n",
    "    cent_dists = dict()\n",
    "    for (movie, frame), tree in tqdm(trees_dict[channel].items()):\n",
    "        centroids = data_dict[channel][movie, frame][spatial_columns].values\n",
    "        distances, _ = tree.query(centroids, k=2)\n",
    "        cent_dists[movie, frame] = distances[:, 1]\n",
    "    cent_dists_dict[channel] = cent_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00dbd2-03bb-4621-855e-7ceae8c5d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `cdist` to calculate nearest neighbor distances (opposite species)\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "exclude_conversions = False #True\n",
    "focuson_conversions = True #False\n",
    "\n",
    "channel1, channel2 = channels\n",
    "keys = f\"{channel1}-{channel1}\", f\"{channel2}-{channel2}\", f\"{channel1}-{channel2}\"\n",
    "\n",
    "min_cent_dists_dict = dict()\n",
    "min_surf_dists_dict = dict()\n",
    "for key in keys:\n",
    "    print(key)\n",
    "    match = re.match(r\"(\\w*)-(\\w*)\", key)\n",
    "    key1, key2 = match.group(1), match.group(2)\n",
    "    \n",
    "    min_cent_dists = dict()\n",
    "    min_surf_dists = dict()\n",
    "    for (movie, frame) in tqdm(movie_frames):\n",
    "        # Get identities of all in-progress conversions\n",
    "        converting = conversions.query(f\"movie == {movie} and overlap_start <= {frame} and overlap_stop >= {frame}\")\n",
    "        if len(converting) > 0:\n",
    "            converting_tracks1, converting_tracks2 = zip(*converting.filter(regex=r\"^track_(APPL1|EEA1)$\").values)\n",
    "        else:\n",
    "            converting_tracks1, converting_tracks2 = tuple(), tuple()\n",
    "        \n",
    "        # Get data for current movie and frame\n",
    "        data1 = data_dict[key1][movie, frame]\n",
    "        data2 = data_dict[key2][movie, frame]\n",
    "        \n",
    "        if exclude_conversions:\n",
    "            data1 = data1.query(f\"track not in {converting_tracks1}\")\n",
    "            data2 = data2.query(f\"track not in {converting_tracks2}\")\n",
    "        \n",
    "        if focuson_conversions:\n",
    "            data1 = data1.query(f\"track in {converting_tracks1}\")\n",
    "            data2 = data2.query(f\"track in {converting_tracks2}\")\n",
    "        \n",
    "        # Get all particle positions\n",
    "        cents1 = data1[spatial_columns].values\n",
    "        cents2 = data2[spatial_columns].values\n",
    "\n",
    "        # Calculate the distances between each point of vector 1 and vector 2\n",
    "        cent_dists = cdist(cents1, cents2)\n",
    "        if key1 == key2:\n",
    "            np.fill_diagonal(cent_dists, np.nan)\n",
    "        \n",
    "        try:\n",
    "            min_indexes = np.nanargmin(cent_dists, axis=1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Calculate minimum centroid and surface distances\n",
    "        min_cent_dists[movie, frame] = list()\n",
    "        min_surf_dists[movie, frame] = list()\n",
    "        for i, j in enumerate(min_indexes):\n",
    "            min_cent_dist = cent_dists[i, j]\n",
    "            if min_cent_dist < 1e-6:\n",
    "                min_surf_dist = np.nan\n",
    "            else:\n",
    "                min_surf_dist = min_cent_dist - (data1.iloc[i]['r_um'] + data2.iloc[j]['r_um'])\n",
    "            min_cent_dists[movie, frame].append(min_cent_dist)\n",
    "            min_surf_dists[movie, frame].append(min_surf_dist)\n",
    "\n",
    "    min_cent_dists_dict[key] = min_cent_dists\n",
    "    min_surf_dists_dict[key] = min_surf_dists\n",
    "\n",
    "# Concatenate all results together\n",
    "min_cent_dist = {k : np.hstack(list(v.values())) for k, v in min_cent_dists_dict.items()}\n",
    "min_surf_dist = {k : np.hstack(list(v.values())) for k, v in min_surf_dists_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1961b-f85d-4462-8074-84ca50c3c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.1\n",
    "binrange = -1, 5\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(2.5, 2.5))\n",
    "for key, color in zip(keys, (cyan, magenta, gold)):\n",
    "    sns.histplot(\n",
    "        data=min_surf_dist[key],\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='count',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_ylim(0, 750)\n",
    "ax.set_xlabel(r\"Nearest Distance ($\\mu$m)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4678e4-647b-4296-9ac8-b8fa55f8290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exclude_conversions and focuson_conversions:\n",
    "    min_surf_dist_converting = copy.deepcopy(min_surf_dist)\n",
    "elif exclude_conversions and not focuson_conversions:\n",
    "    min_surf_dist_nonconverting = copy.deepcopy(min_surf_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0cfe6-0213-415d-bc4d-d30749c36b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.1\n",
    "binrange = -1, 5\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(2.5, 2.5))\n",
    "for data, color in zip((min_surf_dist_nonconverting['APPL1-EEA1'], min_surf_dist_converting['APPL1-EEA1']), (\"#EEEEEE\", \"#111111\")):\n",
    "    sns.histplot(\n",
    "        data=data,\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='count',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_ylim(0, 25000)\n",
    "ax.set_xlabel(r\"Nearest Distance ($\\mu$m)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "#ax.set_title(\"APPL1-EEA1 Nearest Neighbours\")\n",
    "ax.legend((\"No\", \"Yes\"), title=\"Converting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f82dac-d7c4-46a8-a688-eac949f54d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (smoothed histogram)\n",
    "bw_adjust = 0.5\n",
    "binrange = -1, 5\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for key, color in zip(keys, (cyan, magenta, gold)):\n",
    "    sns.kdeplot(\n",
    "        data=min_surf_dist[key],\n",
    "        bw_adjust=bw_adjust,\n",
    "        ax=ax,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel(r\"Nearest Distance ($\\mu$m)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.legend(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a553829-63da-4599-97d0-d93cc2544878",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.3 Calculate local endosome densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98a7b4-c69a-407d-9d8a-eaaf2e7a3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of search radii\n",
    "search_radii = range(1, 11)\n",
    "\n",
    "local_densities = dict()\n",
    "for search_radius in tqdm(search_radii):\n",
    "    search_volume = (4 / 3) * np.pi * search_radius ** 3\n",
    "    \n",
    "    # Calculate local density of endosomes in each channel\n",
    "    densities_dict = dict()\n",
    "    for channel in channels:\n",
    "        densities = dict()\n",
    "        for (movie, frame) in movie_frames:\n",
    "            positions = data_dict[channel][movie, frame][spatial_columns]\n",
    "\n",
    "            # Construct the KDTree using the object positions\n",
    "            tree = cKDTree(positions)\n",
    "\n",
    "            # Calculate the local density for all objects\n",
    "            neighbor_indices = tree.query_ball_point(positions, search_radius)\n",
    "            \n",
    "            # Count number of nearest neighbors within search radius\n",
    "            neighbor_counts = np.asarray([len(v)-1 for v in neighbor_indices])\n",
    "            \n",
    "            # Calculate the local density as the count of neighbors within the search radius\n",
    "            local_density = neighbor_counts / search_volume\n",
    "            \n",
    "            densities[movie, frame] = local_density\n",
    "\n",
    "        densities_dict[channel] = densities\n",
    "\n",
    "    # Concatenate all results together\n",
    "    local_density = {k : np.hstack(list(v.values())) for k, v in densities_dict.items()}\n",
    "    local_densities[search_radius] = local_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3fe25-7a5a-4a8d-84c0-6f557b56a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax_index, (search_radius, local_density) in enumerate(local_densities.items()):\n",
    "    ax = axs[ax_index]\n",
    "    \n",
    "    # Plot final results for all combinations (histogram)\n",
    "    binwidth = 0.02\n",
    "    binrange = 0, 0.5\n",
    "    \n",
    "    for channel, color in zip(channels, (cyan, magenta)):\n",
    "        sns.histplot(\n",
    "            data=local_density[channel],\n",
    "            binwidth=binwidth,\n",
    "            binrange=binrange,\n",
    "            stat='density',\n",
    "            ax=ax,\n",
    "            alpha=0.5,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(binrange)\n",
    "    ax.set_xlabel(r\"Local Density ($\\mu$m$^{-3}$)\")\n",
    "    ax.set_ylabel(\"PDF\")\n",
    "    ax.set_title(fr\"Search Radius = {search_radius:0.1f} $\\mu$m\")\n",
    "    ax.legend(channels)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292952ea-f214-4d99-a48d-27f6ed28d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(4, 2.5))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "search_radius = 3\n",
    "local_density = local_densities[search_radius]\n",
    "\n",
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.02\n",
    "binrange = 0, 0.5\n",
    "\n",
    "for channel, color in zip(channels, (cyan, magenta)):\n",
    "    sns.histplot(\n",
    "        data=local_density[channel],\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='probability',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel(r\"Local Density ($\\mu$m$^{-3}$)\")\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427e715-cd82-444c-8a2e-3b4524a779ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    df = pd.DataFrame(local_densities[3][channel], columns=[channel])\n",
    "    export_csv(df, f\"LocalDensity_{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9aaa6-83da-4a98-b59e-edd581d453da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax_index, (search_radius, local_density) in enumerate(local_densities.items()):\n",
    "    ax = axs[ax_index]\n",
    "    \n",
    "    # Plot final results for all combinations (smoothed histogram)\n",
    "    bw_adjust = 2.5\n",
    "    binrange = 0, 0.5\n",
    "\n",
    "    for channel, color in zip(channels, (cyan, magenta)):\n",
    "        sns.kdeplot(\n",
    "            data=local_density[channel],\n",
    "            bw_adjust=bw_adjust,\n",
    "            ax=ax,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(binrange)\n",
    "    ax.set_xlabel(r\"Endosome Density ($\\mu$m$^{-3}$)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(fr\"Search Radius = {search_radius:0.1f} $\\mu$m\")\n",
    "    ax.legend(channels)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85879407-3c1e-4ec6-8a5d-250f73f96461",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.4 Calculate endosome velocity distributions (moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04cdba-5e7b-40ba-9bbc-75ad269de7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "\n",
    "moving_dict = dict.fromkeys(channels)\n",
    "for channel, data in zip(channels, (tracked1, tracked2)):\n",
    "    moving = {k : list() for k in set(movies)}\n",
    "    for (movie, track), group in tqdm(data.groupby(['movie', 'track'])):\n",
    "        if len(group) < window_size * 2:\n",
    "            continue\n",
    "\n",
    "        displacements = (group\n",
    "                         .filter(regex='(x|y|z)_um')\n",
    "                         .diff(axis=0)\n",
    "                        )\n",
    "        time_steps = (group[['frame']] * frame_rates[movie]).diff()\n",
    "        velocities = (displacements / time_steps.values).dropna()\n",
    "\n",
    "        velocities_moving = velocities.rolling(window_size).mean().dropna()\n",
    "        moving[movie].extend(list(np.sqrt(np.sum(velocities_moving ** 2, axis=1)).values))\n",
    "    moving_dict[channel] = moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37681e38-868f-4382-86d0-22b7e0d465bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.0075\n",
    "binrange = 0, 0.25\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(4, 2.5))\n",
    "for channel, data in moving_dict.items():\n",
    "    sns.histplot(\n",
    "        data=np.hstack(list(data.values())),\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='probability',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=colors[channel],\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel('Velocity ($\\mu$m s$^{-1}$)')\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb8aa2-bcba-45ee-a27b-191eda24229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    df = pd.DataFrame(np.hstack(list(moving_dict[channel].values())), columns=[channel])\n",
    "    export_csv(df, f\"Velocity_{channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3842af0-2287-423f-91f3-3abd0e016676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binrange = 0, 0.25\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for channel, data in moving_dict.items():\n",
    "    sns.kdeplot(\n",
    "        data=np.hstack(list(data.values())),\n",
    "        ax=ax,\n",
    "        color=colors[channel],\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel('Velocity ($\\mu$m s$^{-1}$)')\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492352a-adf3-4c78-a9b8-018019c90651",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k : np.std(np.hstack(list(v.values()))) for k, v in moving_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e772db5-ed44-452b-a22c-3bbfda5f09b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.5 Calculate endosome step size distributions (instantaneous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f1912-696e-4a3a-a5b0-9fc7e29ea1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_dict = dict.fromkeys(channels)\n",
    "for channel, data in zip(channels, (tracked1, tracked2)):\n",
    "    step_sizes = {k : list() for k in set(movies)}\n",
    "    for (movie, track), group in tqdm(data.groupby(['movie', 'track'])):\n",
    "        if len(group) < window_size * 2:\n",
    "            continue\n",
    "\n",
    "        displacements = (group\n",
    "                         .filter(regex='(x|y|z)_um')\n",
    "                         .diff(axis=0)\n",
    "                        )\n",
    "        frame_steps = group[['frame']].diff()\n",
    "        step_sizes[movie].extend(list(np.sqrt(np.sum((displacements / frame_steps.values).dropna() ** 2, axis=1)).values))\n",
    "    step_size_dict[channel] = step_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a6893-de97-4a63-85be-a13fef68cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.1\n",
    "binrange = 0, 1.5\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for channel, data in step_size_dict.items():\n",
    "    sns.histplot(\n",
    "        data=np.hstack(list(data.values())),\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='count',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=colors[channel],\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel('Instantaneous Step Sizes ($\\mu$m frame$^{-1}$)')\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df3de1-0acb-4470-9b87-d08e389f1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binrange = 0, 1.5\n",
    "bw_adjust = 3\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "for channel, data in step_size_dict.items():\n",
    "    sns.kdeplot(\n",
    "        data=np.hstack(list(data.values())),\n",
    "        bw_adjust=bw_adjust,\n",
    "        ax=ax,\n",
    "        color=colors[channel],\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel('Instantaneous Step Sizes ($\\mu$m frame$^{-1}$)')\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000e48b-c919-435d-8a4a-6413f04496ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous step sizes\n",
    "{k : np.mean(np.hstack(list(v.values()))) for k, v in step_size_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f88e76-bbab-4c82-b988-3d4052f398da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous velocities\n",
    "{k : np.mean(np.hstack([(np.array(b) * frame_rates[a]) for a, b in v.items()])) for k, v in moving_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50a6d6-1644-49c2-8795-8611a5f67fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average velocities\n",
    "{k : np.mean(np.hstack(list(v.values()))) for k, v in moving_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee98d2-c479-404e-9b73-69a284274527",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.6 Calculate expected collision frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb6efd-746f-48bf-b923-2cf10ad7196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate collision cross-section of APPL1 and EEA1 endosomes\n",
    "radius1 = tracked1.groupby('movie')['r_um'].mean()\n",
    "radius2 = tracked2.groupby('movie')['r_um'].mean()\n",
    "sigma_ = np.pi * (radius1 + radius2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37476659-b83f-48a3-aad0-8d7bd90267a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_radius = 5\n",
    "search_volume = (4 / 3) * np.pi * search_radius ** 3\n",
    "\n",
    "# Calculate local density of endosomes in each movie and channel\n",
    "densities_dict = dict()\n",
    "for channel in channels:\n",
    "    densities = list()\n",
    "    for (movie, frame) in tqdm(movie_frames):\n",
    "        positions = data_dict[channel][movie, frame][spatial_columns]\n",
    "        \n",
    "        # Construct the KDTree using the object positions\n",
    "        tree = cKDTree(positions)\n",
    "        \n",
    "        # Calculate the local density for all objects\n",
    "        neighbor_indices = tree.query_ball_point(positions, search_radius)\n",
    "        \n",
    "        # Count number of nearest neighbors within search radius\n",
    "        neighbor_counts = np.asarray([len(v)-1 for v in neighbor_indices])\n",
    "        \n",
    "        # Calculate the local density as the count of neighbors within the search radius\n",
    "        local_density = neighbor_counts / search_volume\n",
    "        \n",
    "        # Gather all results into DataFrame\n",
    "        df = data_dict[channel][movie, frame][['movie', 'frame', 'track']]\n",
    "        df['density'] = local_density\n",
    "        \n",
    "        # Append Dataframe\n",
    "        densities.append(df)\n",
    "\n",
    "    densities_dict[channel] = pd.concat(densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d193323-9950-42e8-ae95-d65fe17df704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate local densities of all collision events\n",
    "colliding_densities_dict = dict()\n",
    "for channel in channels:\n",
    "    colliding_densities_dict[channel] = pd.merge(\n",
    "        densities_dict[channel],\n",
    "        collisions[['movie', 'frame', f'track_{channel}']],\n",
    "        left_on=['movie', 'frame', 'track'],\n",
    "        right_on=['movie', 'frame', f'track_{channel}'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6748ff-e4bb-499d-9786-1f25c6017b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.01\n",
    "binrange = 0, 0.25\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13, 5))\n",
    "axs = np.ravel(axs)\n",
    "for ax, channel in zip(axs, channels):\n",
    "    for index, color in enumerate(('gray', 'gold')):\n",
    "        if index == 0:\n",
    "            data = densities_dict[channel]['density']\n",
    "        elif index == 1:\n",
    "            data = colliding_densities_dict[channel]['density']\n",
    "        \n",
    "        sns.histplot(\n",
    "            data=data,\n",
    "            binwidth=binwidth,\n",
    "            binrange=binrange,\n",
    "            stat='density',\n",
    "            ax=ax,\n",
    "            alpha=0.5,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(binrange)\n",
    "    ax.set_xlabel(r\"Local Density ($\\mu$m$^{-3}$)\")\n",
    "    ax.set_title(fr\"{channel}: Search Radius = {search_radius:0.1f} $\\mu$m\")\n",
    "    ax.legend(('all', 'colliding'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7507b-85e3-466b-9c54-417ac2d00953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate local densities of all conversion events\n",
    "converting_densities_dict = dict()\n",
    "for channel in channels:\n",
    "    converting_densities_dict[channel] = pd.merge(\n",
    "        densities_dict[channel],\n",
    "        conversions[['movie', 'overlap_start', f'track_{channel}']],\n",
    "        left_on=['movie', 'frame', 'track'],\n",
    "        right_on=['movie', 'overlap_start', f'track_{channel}'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc3494-d8c1-4cde-a54d-75276137322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 0.01\n",
    "binrange = 0, 0.25\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13, 5))\n",
    "axs = np.ravel(axs)\n",
    "for ax, channel in zip(axs, channels):\n",
    "    for index, color in enumerate(('gray', 'gold')):\n",
    "        if index == 0:\n",
    "            data = densities_dict[channel]['density']\n",
    "        elif index == 1:\n",
    "            data = converting_densities_dict[channel]['density']\n",
    "        \n",
    "        sns.histplot(\n",
    "            data=data,\n",
    "            binwidth=binwidth,\n",
    "            binrange=binrange,\n",
    "            stat='density',\n",
    "            ax=ax,\n",
    "            alpha=0.5,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(binrange)\n",
    "    ax.set_xlabel(r\"Local Density ($\\mu$m$^{-3}$)\")\n",
    "    ax.set_title(fr\"{channel}: Search Radius = {search_radius:0.1f} $\\mu$m\")\n",
    "    ax.legend(('all', 'converting'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c846a1d-014b-4b7b-981e-806e655f3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average number density (of both particles)\n",
    "rho_1 = pd.Series({k : v for k, v in densities_dict['APPL1'].groupby('movie')['density'].mean().items()}, name='rho_')\n",
    "rho_1.index.name = 'movie'\n",
    "rho_2 = pd.Series({k : v for k, v in densities_dict['EEA1'].groupby('movie')['density'].mean().items()}, name='rho_')\n",
    "rho_2.index.name = 'movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d454861-a779-44a7-aac0-96c3bc77995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(rho_1), np.std(rho_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b2d7a-399e-424e-9c77-b411f77375b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean free path of APPL1 and EEA1 endosomes\n",
    "lambda_1 = 1 / (np.sqrt(2) * rho_1 * sigma_)\n",
    "lambda_2 = 1 / (np.sqrt(2) * rho_2 * sigma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9137e8f-ef9e-475b-a334-fb283fc2514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lambda_1), np.mean(lambda_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32641700-161a-426c-9b14-3af9566fd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average displacements (of both particles)\n",
    "disp_1 = pd.Series({k : np.mean(v) for k, v in step_size_dict['APPL1'].items()}, name='displacement')\n",
    "disp_1.index.name = 'movie'\n",
    "disp_2 = pd.Series({k : np.mean(v) for k, v in step_size_dict['EEA1'].items()}, name='displacement')\n",
    "disp_2.index.name = 'movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ab551-8636-4015-8e49-3b6858918063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average time between collisions\n",
    "np.mean(lambda_1 / (disp_1 / pd.Series(frame_rates))), np.mean(lambda_2 / (disp_2 / pd.Series(frame_rates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cee7b-474a-4828-aac8-f75e6685f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the collision frequency of APPL1 and EEA1 endosomes\n",
    "v_rms1 = pd.Series({k : np.mean(v) / frame_rates[k] for k, v in step_size_dict['APPL1'].items()}, name='v_rms')\n",
    "v_rms1.index.name = 'movie'\n",
    "v_rms2 = pd.Series({k : np.mean(v) / frame_rates[k] for k, v in step_size_dict['EEA1'].items()}, name='v_rms')\n",
    "v_rms2.index.name = 'movie'\n",
    "\n",
    "nu_1 = v_rms1 / lambda_1\n",
    "nu_2 = v_rms2 / lambda_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cef9ce-3df2-4b20-93eb-ec3e866d8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average collision frequency of APPL1 and EEA1 endosomes\n",
    "np.mean(nu_1), np.mean(nu_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfa48e-66a1-47f5-8535-dd1ae0ab8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average frame-frame step size of APPL1 endosomes\n",
    "np.mean(v_rms1 * pd.Series(frame_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a9b83-7987-4542-b99d-abddfe90a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average frame-frame step size of EEA1 endosomes\n",
    "np.mean(v_rms2 * pd.Series(frame_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614509ef-4df4-4f23-afab-ab97d5755f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts1 = dict()\n",
    "for movie, group in tracked1.groupby('movie'):\n",
    "    counts1[movie] = group['frame'].value_counts().values[:50]\n",
    "counts1 = pd.Series({k : np.mean(v) for k, v in counts1.items()}, name='counts')\n",
    "counts1.index.name = 'movie'\n",
    "\n",
    "counts2 = dict()\n",
    "for movie, group in tracked2.groupby('movie'):\n",
    "    counts2[movie] = group['frame'].value_counts().values[:50]\n",
    "counts2 = pd.Series({k : np.mean(v) for k, v in counts2.items()}, name='counts')\n",
    "counts2.index.name = 'movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5d89d-2493-4854-b3a0-65d17501f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(counts1), np.mean(counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd73ac-8c18-40d4-adfd-88062b95a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate number of collisions per frame\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(nu_1 * counts1 * pd.Series(frame_rates), density=True)\n",
    "ax.set_xlabel(\"Collisions per Frame\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37901894-2d2d-41ef-a9e8-900b3e3931a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of APPL1 collisions onto EEA1 per unit time (frame)\n",
    "np.mean(nu_1 * counts1 * pd.Series(frame_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013e617-4a5d-4584-ae92-8eac8548b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of EEA1 collisions onto APPL1 per unit time (frame)\n",
    "np.mean(nu_2 * counts2 * pd.Series(frame_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97082000-3c89-4f23-b9ed-58d44e7199c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of confirmed conversions per unit time\n",
    "np.mean(conversions.groupby('movie')['movie'].count() / tracked1[['movie', 'frame']].drop_duplicates().groupby('movie')['frame'].count()) / frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8c249-2fa5-406f-a423-c1aee26e60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate number of collisions per frame\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(nu_2 * counts2 * pd.Series(frame_rates), density=True)\n",
    "ax.set_xlabel(\"Collisions per Frame\")\n",
    "ax.set_ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916e4a1-c58d-45c7-956a-00373eb923ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 9.7 Calculate empirical distribution of times between collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3ab47-7ffe-4ef7-8ed5-1d1d3b874e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_seconds = 240\n",
    "min_surf_dist = -0.25\n",
    "max_surf_dist = +0.0\n",
    "\n",
    "collision_intervals_dict = dict()\n",
    "for channel, tracked in zip(channels, (tracked1, tracked2)):\n",
    "    collision_intervals = list()\n",
    "    collisions_ = collisions.query(f\"surf_dist > {min_surf_dist} and surf_dist < {max_surf_dist}\")\n",
    "    for (movie, track), group in tqdm(collisions_.groupby(['movie', f'track_{channel}'])):\n",
    "        min_frames = min_seconds / frame_rates[movie]\n",
    "        if len(tracked.query(f\"movie == {movie} and track == {track}\")) < min_frames:\n",
    "            continue\n",
    "        if len(group) > 1:\n",
    "            collision_interval = (group['frame']\n",
    "                                  .sort_values()\n",
    "                                  .diff()\n",
    "                                  .dropna()\n",
    "                                  .values\n",
    "                                 ) * frame_rates[movie]\n",
    "        else:\n",
    "            collision_interval = [min_seconds]\n",
    "        collision_intervals.extend(collision_interval)\n",
    "    collision_intervals_dict[channel] = np.asarray(collision_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a72ff2-a08f-4807-8097-61c277903de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k : np.mean(v[v < min_seconds]) for k, v in collision_intervals_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142341e9-d55e-467d-a6c9-4baa0011eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final results for all combinations (histogram)\n",
    "binwidth = 10\n",
    "binrange = 0, min_seconds\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(4, 2.5))\n",
    "for channel, data in collision_intervals_dict.items():\n",
    "    sns.histplot(\n",
    "        data=data[data < min_seconds],\n",
    "        binwidth=binwidth,\n",
    "        binrange=binrange,\n",
    "        stat='probability',\n",
    "        ax=ax,\n",
    "        alpha=0.5,\n",
    "        color=colors[channel],\n",
    "    )\n",
    "\n",
    "ax.set_xlim(binrange)\n",
    "ax.set_xlabel('Time Between Collisions (s)')\n",
    "ax.legend(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62603809-d5fd-46e5-af09-34e6f2534edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in channels:\n",
    "    data = collision_intervals_dict[channel]\n",
    "    df = pd.DataFrame(data[data < min_seconds], columns=[channel])\n",
    "    export_csv(df, f\"MeanCollisionTime_{channel}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
